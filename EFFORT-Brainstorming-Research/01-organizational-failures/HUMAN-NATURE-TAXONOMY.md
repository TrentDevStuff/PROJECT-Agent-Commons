---
created: 2026-02-12T21:00:00Z
updated: 2026-02-12T21:00:00Z
type: research
parent_effort: EFFORT-Brainstorming-Research
research_area: 01-organizational-failures
status: in_progress
backlinks:
  - [[RESEARCH]]
---

# Human Nature Taxonomy: Psychological and Evolutionary Foundations

This document validates, refines, and grounds the initial taxonomy of human tendencies that organizational systems must hedge against. Each tendency is examined through evolutionary psychology, cognitive science, behavioral economics, social psychology, and game theory. The goal is to build a research-backed analytical lens, not an exhaustive literature review -- but with enough depth and citation that claims can be traced to their sources.

---

## Part A: Deep Analysis of Each Tendency

---

### 1. Power-Seeking

**Definition:** The accumulation of control, influence, and decision-making authority beyond what is functionally needed for one's role.

#### Evolutionary Basis

Dominance hierarchies are nearly universal in social mammals. In primate studies (de Waal, 1982, *Chimpanzee Politics*), coalitional power-seeking is a central activity -- not just brute physical dominance, but strategic alliance-building, reciprocal favors, and Machiavellian social maneuvering. Frans de Waal documented chimpanzees forming alliances, betraying allies, and engaging in political behavior indistinguishable in structure (though not in content) from human organizational politics.

From an evolutionary perspective, dominance correlates with reproductive access and resource control. Henrich and Gil-White (2001) distinguish between **dominance** (coercion-based) and **prestige** (skill/knowledge-based) as two separate pathways to social influence in humans. This distinction matters for organizational design: prestige-based hierarchies are relatively functional (the skilled surgeon leads the surgery), while dominance-based hierarchies are the failure mode.

David Buss's work in evolutionary psychology (*The Evolution of Desire*, 1994; *The Handbook of Evolutionary Psychology*, 2005) identifies status-striving as a fundamental human motive shaped by sexual selection. In ancestral environments, higher status males had greater reproductive success. This drive persists even when the reproductive logic no longer applies.

#### Cognitive/Psychological Basis

McClelland's *Need for Power* (nPow) from his three-needs theory (McClelland, 1961, *The Achieving Society*) identifies power motivation as a stable individual difference. People high in nPow are drawn to leadership roles and derive satisfaction from influencing others. Winter (1973) developed power motive scoring and found it predicted leadership emergence -- but also authoritarianism and exploitative behavior when unchecked.

The **endowment effect** for power is particularly insidious: once people have authority, they value it more than they would have paid to acquire it (parallel to Kahneman, Knetsch, and Thaler's, 1990, work on the endowment effect for objects). Maner and Mead (2010) demonstrated experimentally that people in leadership positions engage in self-serving behavior to maintain power, even at the cost of group outcomes. Specifically, leaders excluded competent group members who threatened their position.

#### Organizational Manifestation

The principal-agent problem (Jensen and Meckling, 1976) is the formal economic model: agents (managers) pursue their own interests rather than those of principals (owners). This is power-seeking channeled through organizational structure. Bebchuk and Fried (2004, *Pay Without Performance*) documented how CEO compensation is better explained by managerial power theory than by efficient contracting -- executives effectively set their own pay through captured boards.

#### How Resistant to Institutional Design

**Highly resistant.** Power-seeking is adaptive, strategically flexible, and capable of exploiting any gap in institutional structure. Checks and balances, term limits, and separation of powers all help but are subject to erosion over time. The tendency finds new channels when old ones are blocked (regulatory capture, informal influence networks, information control).

---

### 2. Herd Mentality (Conformity Bias)

**Definition:** Following the crowd, adopting majority positions, and suppressing independent judgment under social pressure.

#### Evolutionary Basis

Conformity was strongly adaptive in ancestral environments. Boyd and Richerson (1985, *Culture and the Evolutionary Process*) developed the formal evolutionary model: **conformist transmission** -- copying the majority -- is an efficient heuristic when individual learning is costly or dangerous. If most people in your tribe avoid a particular berry, conforming to that behavior is cheaper than testing it yourself. The cost of independent judgment (death by poisoning) vastly exceeded the cost of conformity (occasionally missing a good berry).

Henrich (2016, *The Secret of Our Success*) argues that conformity and cultural learning are the central human adaptation -- more important than individual intelligence. Humans succeed not because we are smart individually, but because we are excellent at copying successful behaviors. This makes conformity deeply wired, not a superficial social effect.

#### Cognitive/Psychological Basis

Asch's conformity experiments (1951, 1956) are foundational: approximately 75% of participants conformed to an obviously incorrect group judgment at least once, and 25% conformed consistently. This occurs even with strangers on trivial judgments.

Informational social influence (Sherif, 1935, autokinetic effect) is rational: when you lack information, the crowd is a reasonable signal. Normative social influence (Asch, 1956) is social pressure: you conform to be accepted even when you know the crowd is wrong. Both operate in organizations.

Janis's **groupthink** model (1972, *Victims of Groupthink*) identified the organizational failure mode: cohesive groups suppress dissent, fail to consider alternatives, and develop illusions of invulnerability. Case studies include the Bay of Pigs, Challenger disaster, and numerous corporate failures where dissenting voices existed but were silenced.

Sunstein (2003, *Why Societies Need Dissent*) and Sunstein and Hastie (2015, *Wiser*) documented how group deliberation often amplifies rather than corrects individual biases -- groups move toward more extreme versions of their initial tendency (group polarization).

#### Organizational Manifestation

Market bubbles, strategic bandwagoning, failure to raise concerns in meetings, code of silence around problems. Enron's culture of conformity is a textbook case: employees who raised concerns were marginalized or terminated, while those who conformed to the prevailing optimism were rewarded.

#### How Resistant to Institutional Design

**Moderately resistant.** Institutional structures can help: anonymous feedback, devil's advocate roles, red teams, prediction markets, and structured dissent protocols (like Delphi method) all reduce conformity pressure. But these require the institution itself to value dissent, which is countercultural in most organizations.

---

### 3. Short-Term Bias (Temporal Discounting)

**Definition:** Systematically prioritizing immediate or near-term outcomes over longer-term consequences, even when the long-term outcome is objectively superior.

#### Evolutionary Basis

In ancestral environments, the future was radically uncertain. Organisms that consumed available resources immediately outcompeted those that saved for a future they might not reach. Evolutionary biologists call this the **discount rate**: the rate at which future payoffs are devalued relative to present ones. In environments with high mortality, high discount rates are rational (Rogers, 1994).

Human temporal discounting is **hyperbolic**, not exponential (Ainslie, 1975, 2001; Laibson, 1997). Exponential discounting (the economists' rational model) implies consistent preferences over time. Hyperbolic discounting implies preference reversals: you prefer $110 in 31 days over $100 in 30 days, but you prefer $100 today over $110 tomorrow. This produces the familiar pattern of intending to exercise tomorrow but never doing it today. Thaler (1981) provided early experimental evidence; McClure et al. (2004) showed different brain regions (limbic for immediate, prefrontal for delayed) compete to produce these preference reversals.

#### Cognitive/Psychological Basis

Kahneman's System 1/System 2 framework (2011, *Thinking, Fast and Slow*) maps directly: System 1 (fast, automatic, emotional) weights present rewards heavily. System 2 (slow, deliberate, rational) can calculate long-term consequences but is effortful and easily overridden. Under cognitive load, time pressure, or emotional arousal -- common in organizational settings -- System 1 dominates.

The **present bias** (O'Donoghue and Rabin, 1999) model captures this formally: people apply an extra discount to any future period relative to the present. This produces procrastination, under-saving, and short-term organizational thinking.

#### Organizational Manifestation

Quarterly earnings pressure in corporations. Election-cycle thinking in democracies. Failure to invest in infrastructure, climate mitigation, R&D, or training. The tragedy of the time horizon: every individual decision-maker faces incentives weighted toward the short term, even when the collective long-term cost is enormous.

Stein (1989) formalized how stock market pressure creates corporate short-termism: managers sacrifice long-term value to meet quarterly expectations because the market discounts future earnings at rates reflecting uncertainty about management tenure.

#### How Resistant to Institutional Design

**Resistant but addressable.** Constitutional provisions, long-term endowments, vesting schedules, and lock-up periods are all institutional hedges. Sovereign wealth funds, constitutional courts, and central bank independence are designed specifically to insulate long-term decisions from short-term pressures. The hedges work -- but they themselves are vulnerable to being overridden when short-term pressure is intense enough.

---

### 4. Free-Riding

**Definition:** Benefiting from collective goods or efforts without contributing proportionally to their creation or maintenance.

#### Evolutionary Basis

The free-rider problem is the core challenge of cooperation theory in biology. Trivers (1971) formalized **reciprocal altruism**: cooperation evolves when organisms can detect and punish cheaters. Axelrod's (1984, *The Evolution of Cooperation*) iterated prisoner's dilemma tournaments demonstrated that **tit-for-tat** strategies (cooperate first, then reciprocate) could sustain cooperation -- but only when interactions were repeated and cheating was detectable.

The critical insight: cooperation is not natural in the sense of being automatic. It is natural in the sense of being an evolved strategy that requires specific conditions (repeated interaction, detection, punishment). Remove those conditions and free-riding dominates. This is why free-riding is such a persistent organizational problem -- large organizations often lack the conditions that sustain cooperation in small groups.

Cosmides and Tooby (1992) demonstrated that humans have a specialized cognitive module -- a **cheater detection mechanism** -- that is far more efficient at detecting social contract violations than logically equivalent non-social reasoning problems (Wason selection task experiments). We are wired to spot free-riders -- but the wiring evolved for small groups where everyone was visible.

#### Cognitive/Psychological Basis

Latane, Williams, and Harkins (1979) documented **social loafing**: individual effort decreases as group size increases. In a rope-pulling experiment, individuals exerted 18% less effort in pairs and 37% less in groups of six compared to pulling alone. This is not strategic free-riding but unconscious effort reduction.

Olson (1965, *The Logic of Collective Action*) provided the economic framework: in large groups, the individual cost of contributing exceeds the individual benefit of the marginal contribution, so rational actors free-ride. The larger the group, the worse the problem. This is why small teams outperform large committees.

Public goods experiments (Isaac, Walker, and Thomas, 1984; Ledyard, 1995) consistently find that cooperation in public goods games starts at 40-60% of optimal and declines to 10-20% over repeated rounds -- unless punishment mechanisms are introduced, which restore cooperation (Fehr and Gachter, 2000, 2002).

#### Organizational Manifestation

Social loafing in teams, tragedy of the commons, voter apathy (Downs, 1957, *An Economic Theory of Democracy*: the paradox of voting), tax evasion, open-source contributor asymmetry (1% create, 99% consume).

#### How Resistant to Institutional Design

**Moderately resistant.** Monitoring, contribution tracking, proportional rewards, and graduated sanctions (Ostrom's design principles) all help. Small team size is the most effective hedge. But in large organizations or public systems, free-riding is persistent because the conditions for detection and punishment degrade.

---

### 5. Tribalism (In-Group Bias)

**Definition:** Preferential treatment of in-group members and hostility, suspicion, or indifference toward out-group members.

#### Evolutionary Basis

Hamilton's (1964) **inclusive fitness** theory provides the genetic foundation: organisms favor genetic relatives. But human tribalism extends far beyond kinship. Evolutionary psychologists (Cosmides and Tooby, 1992; Kurzban, Tooby, and Cosmides, 2001) argue that humans evolved **coalitional psychology** -- the ability to form, track, and compete as groups. This was adaptive because inter-group competition was a primary selection pressure in human evolution.

Choi and Bowles (2007) modeled the co-evolution of in-group altruism and out-group hostility ("parochial altruism"), finding that the two traits reinforce each other: groups with both internal cooperation and external hostility outcompete groups with either trait alone. This suggests tribalism is not a bug but an evolved package deal: you cannot have strong in-group cooperation without some out-group hostility.

Dunbar's number (~150) reflects the cognitive limit on stable social relationships. In groups larger than this, tribal sub-grouping is virtually inevitable because we cannot maintain personal relationships with everyone.

#### Cognitive/Psychological Basis

Tajfel's **minimal group paradigm** (Tajfel et al., 1971) is among the most replicated findings in social psychology: people assigned to arbitrary groups (based on coin flips or art preferences) immediately show in-group favoritism in resource allocation. No real conflict, no history, no material interest -- the mere fact of categorization triggers tribal behavior.

Haidt's **moral foundations theory** (2012, *The Righteous Mind*) identifies loyalty/betrayal as one of six innate moral foundations. In-group loyalty is not learned -- it is a moral intuition that precedes and shapes reasoning. Haidt argues that liberal-conservative political division maps onto differential weighting of moral foundations, with conservatives placing greater emphasis on loyalty, authority, and sanctity.

Sherif's **Robbers Cave experiment** (1954) demonstrated how rapidly inter-group hostility can be created (and resolved) through competition for shared resources. The implication for organizations: structural competition between groups (departments, divisions, offices) activates tribal psychology regardless of individual intentions.

#### Organizational Manifestation

Departmental silos, not-invented-here syndrome, national and regional chauvinism in multinationals, factionalism in political parties, nepotism, cronyism, discrimination in hiring. The "us vs. them" dynamic in labor-management relations, mergers (culture clashes), and cross-functional projects.

#### How Resistant to Institutional Design

**Highly resistant.** Tribalism is deeply wired and activates automatically. Superordinate goals (Sherif's solution in Robbers Cave) and cross-cutting team structures help but require constant maintenance. Diverse representation mandates, rotation programs, and shared identity creation (military basic training as identity replacement) are partial hedges. But any organizational boundary becomes a potential tribal boundary.

---

### 6. Rent-Seeking

**Definition:** Extracting value from a system without creating proportional value -- manipulating the rules, gatekeeping, or exploiting positional advantages.

#### Evolutionary Basis

Rent-seeking is less a distinct evolutionary drive and more a **behavioral strategy** that emerges from the combination of other drives (power-seeking, loss aversion, and environmental opportunity). In evolutionary terms, it parallels **kleptoparasitism** -- organisms that steal resources rather than gathering them independently (e.g., skuas stealing food from other seabirds). This strategy is viable when the cost of production exceeds the cost of extraction and the risk of punishment is low.

From a game-theoretic perspective, rent-seeking is a Nash equilibrium response to certain institutional structures: when it is cheaper to lobby for a share of existing value than to create new value, rational actors will lobby. Tullock (1967) formalized this in "The Welfare Costs of Tariffs, Monopolies, and Theft," and Krueger (1974) coined the term "rent-seeking."

#### Cognitive/Psychological Basis

Rent-seeking exploits the cognitive bias toward **system justification** (Jost and Banaji, 1994): people tend to perceive existing arrangements as legitimate. When someone occupies a gatekeeping position, both they and others tend to justify the position's existence, even when it adds no value. This is compounded by **effort justification** (Festinger, 1957): having invested effort in obtaining a position, the holder rationalizes its importance.

The psychological capacity for rent-seeking is also enabled by **moral disengagement** (Bandura, 1999): diffusing responsibility ("everyone does it"), displacing blame ("the system makes me do it"), or dehumanizing those being extracted from.

#### Organizational Manifestation

Middle management layers that impede rather than facilitate. Regulatory capture where regulated industries write the rules. Patent trolling. Platform monopolies extracting above-competitive rents. Real estate speculation. Professional licensing that restricts supply beyond what quality requires.

#### How Resistant to Institutional Design

**Moderately to highly resistant.** Competition and market mechanisms are the primary hedges, but rent-seekers invest in degrading competition (lobbying, regulatory capture). Sunset clauses, mandatory competition reviews, and transparent value-attribution systems help. But rent-seeking is particularly insidious because the rent-seeker has concentrated incentives to protect their position, while the cost is diffused across many people who each lack incentive to fight it (Olson's concentrated vs. diffuse interests).

---

### 7. Status-Seeking

**Definition:** Pursuing rank, prestige, titles, and social position as ends in themselves, rather than as byproducts of genuine contribution.

#### Evolutionary Basis

Status pursuit is one of the most robust findings in evolutionary psychology. Across cultures, higher status correlates with greater reproductive success, better health, and longer life (Sapolsky, 2004, *Why Zebras Don't Get Ulcers*; Marmot, 2004, *The Status Syndrome*). The Whitehall Studies (Marmot et al., 1991) found that British civil servants' mortality rates correlated more strongly with their rank in the hierarchy than with income, smoking, or other traditional risk factors.

Anderson, Hildreth, and Howland (2015) found that the desire for status is a fundamental human motive on par with the need for belonging. Henrich and Gil-White (2001) identify **prestige** as a distinctly human status mechanism (vs. dominance): humans freely confer status on those with valuable skills or knowledge, creating an incentive to develop and share expertise. The organizational failure occurs when the prestige system is corrupted -- when signals of status (titles, corner offices, credentials) become disconnected from actual competence.

#### Cognitive/Psychological Basis

**Social comparison theory** (Festinger, 1954) holds that humans constantly evaluate themselves relative to others. Importantly, status satisfaction is primarily relative, not absolute (Frank, 1985, *Choosing the Right Pond*; Solnick and Hemenway, 1998, found people prefer $50K in a world where others earn $25K over $100K in a world where others earn $250K).

The **Peter Principle** (Peter and Hull, 1969) -- people are promoted until they reach their level of incompetence -- is not just an observation but a prediction of status-seeking systems: when promotion is the primary status reward, people pursue it regardless of fitness for the new role.

**Credential inflation** reflects status competition: as more people obtain bachelor's degrees, the signal value diminishes, driving demand for master's degrees, then doctorates, in an arms race that serves individual status competition but collective waste.

#### Organizational Manifestation

Title inflation, credential requirements unrelated to job performance, empire-building (measured by team size rather than output), office politics, performative work (looking busy vs. being productive), virtue signaling in organizational contexts.

#### How Resistant to Institutional Design

**Resistant but redirectable.** Status-seeking itself may be ineradicable, but it can be channeled. If the status system rewards contribution (open-source reputation, contribution tracking, transparent impact metrics), status-seeking becomes productive. The failure is when status signals become decoupled from value creation. Flat organizations do not eliminate status-seeking; they just make it covert and unaccountable (Freeman, 1972, "The Tyranny of Structurelessness").

---

### 8. Loss Aversion

**Definition:** Weighting losses more heavily than equivalent gains, protecting existing positions and possessions over pursuing potentially superior alternatives.

#### Evolutionary Basis

Loss aversion has clear evolutionary logic: in resource-scarce ancestral environments, losing a reliable food source could mean death, while gaining an additional food source was nice but not existential. The asymmetry in survival consequences produces asymmetric risk weighting. McDermott, Fowler, and Smirnov (2008) developed an evolutionary model showing that loss aversion is the optimal strategy in environments with variable resources near the survival threshold.

#### Cognitive/Psychological Basis

Kahneman and Tversky's **prospect theory** (1979) is the foundational work: losses loom roughly twice as large as equivalent gains (lambda approximately 2.0-2.5). This is not a learned behavior or a cultural artifact -- it appears across cultures and age groups (though the magnitude varies).

The **endowment effect** (Thaler, 1980; Kahneman, Knetsch, and Thaler, 1990) is the direct organizational implication: people value what they already have more than identical things they do not have. Applied to organizations, this means people over-value existing programs, departments, strategies, and processes simply because they exist.

**Status quo bias** (Samuelson and Zeckhauser, 1988) is the decision-level manifestation: when presented with options, people disproportionately choose the current state. This is distinct from rational conservatism (where the status quo has proven itself) -- status quo bias persists even when the current state was arbitrarily assigned.

Kahneman and Lovallo (1993) describe **loss aversion in managerial decision-making**: managers reject positive-expected-value projects because they fear the blame from a visible loss more than they value the credit from an equivalent gain. This produces systematic organizational under-investment in innovation and change.

#### Organizational Manifestation

Resistance to reorganization, sunk cost continuation (not the same as loss aversion but related -- Arkes and Blumer, 1985), NIMBYism, incumbency advantages in internal resource allocation, Christensen's innovator's dilemma (existing customers and revenue streams prevent pursuit of disruptive opportunities).

#### How Resistant to Institutional Design

**Moderately resistant.** Default options can be set to favor change (opt-out rather than opt-in). Sunset clauses force active recommitment rather than passive continuation. Zero-based budgeting fights status quo allocation. But loss aversion in humans remains the fundamental obstacle to organizational adaptation. Every restructuring must overcome the loss aversion of every person whose current position is threatened.

---

### 9. Information Hoarding

**Definition:** Withholding, restricting, or selectively sharing information to maintain personal advantage, power, or indispensability.

#### Evolutionary Basis

Information asymmetry is a resource. In ancestral environments, knowing where food sources were, understanding social dynamics, or possessing specialized skills conferred survival advantages. Sharing information is an altruistic act that faces the same cooperative dilemmas as any other form of sharing -- it requires conditions of reciprocity and trust.

Trivers' (1971) reciprocal altruism framework applies: information sharing evolves when it is reciprocated. In environments where sharing is exploited without reciprocation, hoarding is the rational strategy. Dunbar (1996, *Grooming, Gossip, and the Evolution of Language*) argues that gossip -- selective information sharing -- is itself a social bonding mechanism and a tool for reputation management.

#### Cognitive/Psychological Basis

**Informational power** is one of French and Raven's (1959) five bases of social power. People intuitively understand that knowledge is leverage. Pfeffer (1992, *Managing with Power*) documents how information control is the primary political tool in organizations.

The **knowledge is power** heuristic is reinforced by organizational reward systems that frequently reward knowledge possession rather than knowledge sharing. When promotions depend on being the person who knows, sharing that knowledge undermines your position.

Akerlof's (1970) **market for lemons** and Stiglitz's information economics demonstrate the structural incentives: information asymmetry benefits the informed party, creating natural incentives to maintain the asymmetry.

#### Organizational Manifestation

Departmental silos, opacity in decision-making, "need-to-know" cultures, expertise hoarding for job security, asymmetric information in negotiations (seller knows more than buyer), obfuscation of financial data, insider trading.

#### How Resistant to Institutional Design

**Moderately resistant.** Transparency mandates, open documentation cultures (open-source as a model), rotation programs, and knowledge management systems all help. But the incentive to hoard persists whenever organizational rewards are tied to individual knowledge possession. The most effective hedge is making sharing more rewarding than hoarding -- contribution-tracking systems, peer recognition, and cultures that celebrate teaching over knowing.

---

### 10. Self-Deception

**Definition:** The unconscious or semi-conscious process of rationalizing self-interested behavior as serving collective or moral purposes.

#### Evolutionary Basis

Trivers (2011, *The Folly of Fools*) presents the most developed evolutionary theory of self-deception: we deceive ourselves in order to deceive others more effectively. If you genuinely believe your self-serving behavior is altruistic, you will be more convincing when defending it, because you will not display the physiological signals of lying. Self-deception co-evolved with the capacity to detect deception in others.

Von Hippel and Trivers (2011) elaborated on this theory with experimental evidence: self-deception reduces the cognitive load of maintaining lies and allows people to pass detection by others. The evolutionary arms race between deception and deception-detection produced organisms that can genuinely fool themselves.

#### Cognitive/Psychological Basis

**Confirmation bias** (Wason, 1960; Nickerson, 1998) is the primary cognitive mechanism: people seek, interpret, and remember information that confirms their existing beliefs. When your existing belief is "I am a good person acting for good reasons," you will find evidence to confirm that and dismiss evidence to the contrary.

**Motivated reasoning** (Kunda, 1990) is the broader framework: when people have a desired conclusion, their reasoning processes are biased toward reaching that conclusion. Importantly, this is not conscious dishonesty -- the reasoning genuinely feels objective to the person doing it.

**Cognitive dissonance** (Festinger, 1957; Festinger, Riecken, and Schachter, 1956, *When Prophecy Fails*) provides the mechanism: when behavior conflicts with self-image, the self-image is revised less often than the interpretation of the behavior. A CEO extracting excessive compensation does not think "I am exploiting my position" but "I am being fairly compensated for my exceptional contribution."

Haidt's **social intuitionist model** (2001) is particularly relevant: moral judgments are post-hoc rationalizations of intuitive reactions, not the products of deliberate reasoning. People reach the conclusion first (emotionally) and construct the justification second (cognitively). This means that self-deception is not an aberration of human reasoning but its default mode for moral and self-relevant judgments.

#### Organizational Manifestation

"What's good for General Motors is good for the country." Mission-statement performativity where the stated mission bears no relation to actual behavior. Greenwashing. Diversity theater. The elaborate justifications produced for executive compensation, monopolistic behavior, worker exploitation, and environmental destruction.

At the organizational level, **institutional isomorphism** (DiMaggio and Powell, 1983) can become a form of collective self-deception: organizations adopt structures and practices not because they are effective but because they signal legitimacy, and they genuinely believe these practices are chosen for effectiveness.

#### How Resistant to Institutional Design

**Extremely resistant.** Self-deception is the tendency that protects all other tendencies from correction. It is the immune system of self-interest. External checks (auditors, whistleblower protections, independent review, adversarial processes) are the primary hedge. Transparency helps but is insufficient because people can look at transparent data and still rationalize. The most effective institutional hedge is creating structures where self-interest and collective interest genuinely align, so self-deception becomes less necessary.

---

## Part B: Overlap Analysis -- Are These Truly Distinct?

The ten tendencies in the initial taxonomy are not fully independent. They cluster around deeper drives and interact in systematic ways.

### Proposed Deep Structure

At the most fundamental level, three **root drives** underlie most of the ten tendencies:

1. **Resource Acquisition** (getting more) -- Drives power-seeking, rent-seeking, status-seeking, free-riding
2. **Threat Avoidance** (not losing what you have) -- Drives loss aversion, information hoarding, tribalism
3. **Cognitive Economy** (thinking less) -- Drives herd mentality, short-term bias, self-deception

These map roughly to evolutionary fundamentals: acquire resources (survival, reproduction), avoid threats (survival), and conserve cognitive energy (efficiency in all the above).

### Specific Overlap Relationships

**Rent-seeking = Power-seeking + Loss aversion + Institutional opportunity.** Rent-seeking is not a distinct psychological drive -- nobody has a "rent-seeking instinct." It is a behavioral strategy that emerges when power-seekers can exploit institutional structures and loss aversion motivates them to protect their extracted position. It belongs in the taxonomy because the *behavioral pattern* is distinct and recognizable, even though the underlying psychology is composite.

**Status-seeking overlaps heavily with power-seeking** but is distinguishable. Power-seeking is about control (ability to determine outcomes). Status-seeking is about position (being recognized as high-rank). A person can seek status without power (honorary titles, prestige appointments) or power without status (grey eminences, behind-the-scenes operators). In organizations, they often co-occur but create different failure modes: status-seeking produces title inflation and credential arms races; power-seeking produces hierarchy capture and control accumulation.

**Information hoarding is instrumental to power-seeking.** It is rarely pursued for its own sake -- it is a strategy for maintaining power, status, or indispensability. However, it manifests so distinctively in organizations (silos, opacity, need-to-know culture) that it warrants separate treatment in the taxonomy.

**Self-deception is meta-level -- it protects all other tendencies from self-correction.** It is not a resource-seeking or threat-avoidance behavior itself but a cognitive mechanism that prevents people from recognizing their other self-interested behaviors. This makes it uniquely dangerous: you can design institutions to check power-seeking, but if the power-seekers genuinely believe they are serving the collective good, they will resist those checks as unjust constraints.

**Herd mentality and tribalism share conformity as a common element** but operate differently. Herd mentality is conformity to the *majority* or *crowd*. Tribalism is loyalty to the *in-group* even against the majority. They can work in opposite directions: herd mentality might push you to follow a crowd your tribe opposes. But both suppress independent judgment in favor of social alignment.

### Revised Structural Model

```
ROOT DRIVES
├── Resource Acquisition
│   ├── Power-seeking (control over outcomes)
│   ├── Status-seeking (position in hierarchy)
│   ├── Rent-seeking [composite: power + loss aversion + opportunity]
│   └── Free-riding [defection strategy when detection is low]
├── Threat Avoidance
│   ├── Loss aversion (protecting existing resources/position)
│   ├── Tribalism (protection through group solidarity)
│   └── Information hoarding [instrumental: protecting advantage]
├── Cognitive Economy
│   ├── Herd mentality (outsourcing judgment to the crowd)
│   ├── Short-term bias (discounting complex future consequences)
│   └── Self-deception (avoiding costly self-revision)
```

**Assessment:** The original ten should be retained in the working taxonomy despite overlaps, because each produces distinct organizational failure modes that require distinct hedges. But understanding the deep structure helps predict which tendencies will be hardest to hedge (those rooted in multiple drives are more persistent) and which will co-occur (clustered tendencies will compound).

---

## Part C: Missing Tendencies

The initial taxonomy has significant gaps. The following should be added:

### 11. Confirmation Bias / Motivated Reasoning

**Why it's missing and why it matters:** Partially covered under self-deception, but confirmation bias operates even in non-self-serving contexts. People seek confirming evidence for *any* existing belief, not just self-serving ones. In organizations, this produces strategic persistence long after evidence suggests a pivot, attachment to initial plans, and resistance to disconfirming data.

**Key research:** Wason (1960), Nickerson (1998), Kunda (1990). Lord, Ross, and Lepper (1979) demonstrated that people evaluate identical evidence differently depending on whether it confirms or disconfirms their prior beliefs.

**Organizational failure mode:** Pursuing failing strategies because evidence is filtered through confirming lens. Escalation of commitment (Staw, 1976). Institutional blindness to emerging threats.

**Distinct from self-deception because:** Self-deception involves rationalizing self-interest as virtue. Confirmation bias can operate on beliefs that are neither self-serving nor self-protective -- people just resist updating beliefs they hold for any reason.

### 12. Diffusion of Responsibility / Bystander Effect

**Why it's missing and why it matters:** Related to free-riding but psychologically distinct. Free-riding is about not contributing to collective goods. Diffusion of responsibility is about not acting when action is needed because others could act. In organizations, this produces the phenomenon where everyone sees a problem, nobody owns it, and disaster results.

**Key research:** Darley and Latane (1968, bystander effect), Milgram (1963, obedience to authority as a form of responsibility diffusion -- "I was just following orders"), Zimbardo (2007, *The Lucifer Effect*) on how situational factors and role diffusion lead to moral failures.

**Organizational failure mode:** Safety violations where everyone assumes someone else will flag the issue. Ethical failures where responsibility is diffused through chains of command. The "not my department" phenomenon.

### 13. Overconfidence / Dunning-Kruger Effect

**Why it's missing and why it matters:** Humans systematically overestimate their own abilities, knowledge, and judgment. This is not a strategic behavior but a cognitive bias, and it produces catastrophic organizational failures.

**Key research:** Dunning and Kruger (1999) showed that low-ability individuals overestimate their competence most severely. Kahneman (2011) identifies overconfidence as "the most significant of the cognitive biases." Moore and Healy (2008) distinguish three types: overestimation (of absolute ability), overplacement (of relative ability), and overprecision (excessive certainty in beliefs).

**Organizational failure mode:** Overambitious strategy, underestimation of risks, insufficient safety margins, leadership by the confidently incompetent, failure to seek expertise. Closely related to hubris as a driver of corporate failure (Hayward and Hambrick, 1997, on CEO hubris and acquisition premiums).

### 14. Envy / Spite (Zero-Sum Thinking)

**Why it's missing and why it matters:** Humans sometimes prefer outcomes where others lose, even at a cost to themselves. This is spite: accepting a worse outcome to prevent someone else from getting a better one. It is closely related to envy (distress at others' advantage) and zero-sum thinking (the belief that one person's gain is another's loss).

**Key research:** Ultimatum game experiments (Guth, Schmittberger, and Schwarze, 1982) consistently find that people reject unfair offers even though rejection means getting nothing -- they prefer zero to an unfair split. Fehr and Schmidt (1999) formalized inequality aversion. Zizzo and Oswald (2001) found that people will pay to destroy others' wealth. Smith and Kim (2007) reviewed envy research.

**Organizational failure mode:** Blocking others' promotions, opposing beneficial changes because someone else benefits more, zero-sum internal competition that destroys total value, "crabs in a bucket" dynamics. Also drives resistance to inequality-reducing reforms when people perceive others gaining relatively more.

### 15. Moral Hazard / Externalization of Costs

**Why it's missing and why it matters:** When people are insulated from the consequences of their decisions (by insurance, limited liability, organizational hierarchy, or distance from impact), they take excessive risks and externalize costs.

**Key research:** Arrow (1963) on moral hazard in insurance. The entire field of environmental economics deals with cost externalization. Taleb's *Skin in the Game* (2018) argues that the separation of decision-making from consequences is the single most important source of systemic risk.

**Organizational failure mode:** Executive risk-taking with other people's money. Environmental destruction. The 2008 financial crisis as moral hazard made manifest (loan originators bearing no default risk). Military leaders risking soldiers' lives. Any principal-agent structure where the agent does not bear the consequences.

### 16. Empire-Building

**Why it's missing and why it matters:** Related to power-seeking and status-seeking but distinct enough in organizational manifestation. Empire-building is the specific tendency to grow one's scope of control (team size, budget, number of direct reports) regardless of whether that growth creates value.

**Key research:** Niskanen (1971, *Bureaucracy and Representative Government*) modeled budget-maximizing bureaucrats. Williamson (1964) on managerial discretion. Parkinson's Law (1955) -- "work expands to fill the time available" -- is the popular expression of this tendency.

**Organizational failure mode:** Bureaucratic bloat, administrative overhead, organizational complexity that exceeds the coordination requirements of the actual work. Every unnecessary management layer is evidence of empire-building.

### Tendencies Considered but Not Added

**Sunk cost fallacy:** Important but better understood as a manifestation of loss aversion applied to past investments. Not a distinct drive.

**Anchoring bias:** Important in decision-making but less relevant to organizational structural failure. More of a pricing/negotiation phenomenon.

**Authority deference:** Milgram's obedience findings are critical but may be better categorized as a variant of herd mentality/conformity applied to vertical (authority) rather than horizontal (peer) social pressure.

---

## Part D: Hierarchy of Destructiveness

Based on the research, the tendencies can be ranked by how destructive they are to organizational systems and how resistant they are to institutional hedges.

### Tier 1: Most Fundamental and Destructive

These are the "master tendencies" that enable and amplify all others:

**1. Self-Deception** -- The most dangerous tendency because it prevents correction of all other tendencies. An organization can survive power-seekers if it can identify them. It cannot survive power-seekers who genuinely believe they are serving the mission, because every check will be resisted as unjust. Self-deception is the immune system of organizational pathology.

**2. Power-Seeking** -- The tendency that, once successful, corrupts the institutional hedges themselves. A power-seeker who captures the governance mechanism can disable every other hedge. This is why checks and balances are necessary but insufficient: they must be robust enough to resist capture by the very people they constrain.

**3. Short-Term Bias** -- The tendency that prevents organizations from investing in their own survival. Even when people can see long-term threats, the psychological weight of immediate concerns overwhelms action. Climate change is the species-level example; corporate disruption is the organizational-level example.

### Tier 2: Highly Destructive, Partially Hedgeable

**4. Tribalism** -- Deeply wired, activates automatically, and degrades cross-group cooperation. But somewhat addressable through superordinate goals, shared identity, and structural integration.

**5. Free-Riding** -- Persistent in large groups but effectively hedged by monitoring, small teams, and contribution tracking. The problem is that these hedges have scale limits.

**6. Loss Aversion** -- The drag on organizational adaptation. Responsible for the pattern where organizations see the threat, understand the threat, and fail to act on the threat. Hedgeable through structural mechanisms (sunset clauses, zero-based review) but persistent at the individual level.

### Tier 3: Destructive but More Amenable to Design

**7. Herd Mentality** -- Dangerous in specific contexts (bubbles, groupthink) but addressable through institutional structures that protect dissent.

**8. Status-Seeking** -- Destructive when decoupled from contribution, but redirectable. Well-designed reputation and contribution systems can channel status-seeking productively.

**9. Information Hoarding** -- Instrumental behavior that responds to incentive redesign. Transparency mandates and knowledge-sharing rewards are reasonably effective.

**10. Rent-Seeking** -- Composite behavior that responds to structural competition, sunset clauses, and transparency. But requires constant vigilance because rent-seekers invest in weakening their own hedges.

### Tier 4: Added Tendencies

**11-16.** Confirmation bias, diffusion of responsibility, overconfidence, envy/spite, moral hazard, and empire-building are all destructive but generally subsidiary to the Tier 1-2 tendencies. They create specific failure modes rather than systemic corruption.

### The Compounding Hierarchy

The most dangerous aspect is not any single tendency but the compounding pattern:

```
Self-deception enables → Power-seeking proceeds unchecked →
  Power-seekers capture governance →
    Loss aversion protects captured positions →
      Tribalism creates defensive factions →
        Information hoarding protects faction interests →
          Free-riders proliferate because monitoring degrades →
            Short-term bias prevents long-term corrective action →
              System rigidity → Collapse or slow decay
```

This is the general failure pattern. Every specific organizational failure is a variation on this sequence.

---

## Part E: Positive Tendencies to Harness

The taxonomy would be incomplete -- and the design implications dangerously pessimistic -- without accounting for the powerful prosocial tendencies that also evolved in humans. Organizational design should not just hedge against the negative; it should actively harness the positive.

### 1. Reciprocity

**Research basis:** Trivers (1971) on reciprocal altruism. Cialdini (2001, *Influence*) on the reciprocity norm as the most powerful social influence principle. Axelrod (1984) on cooperation in iterated games. Berg, Dickhaut, and McCabe (1995) trust game experiments showing that strangers extend trust and reciprocate at rates far above rational self-interest predictions.

**Key insight:** Humans are conditional cooperators (Fischbacher, Gachter, and Fehr, 2001). Most people will cooperate if they believe others are cooperating. The design challenge is creating credible signals of cooperation to activate this tendency.

**Design implication:** Systems that make cooperation visible and reciprocation trackable activate this drive. Contribution tracking, reputation systems, and transparent mutual benefit create positive feedback loops.

### 2. Fairness Instinct

**Research basis:** Ultimatum game rejections (Guth et al., 1982) demonstrate that people sacrifice their own material interest to punish unfairness. Fehr and Schmidt (1999) formalized inequality aversion. The ultimatum game result is cross-cultural (Henrich et al., 2001, *In Search of Homo Economicus*, studied 15 small-scale societies and found that offers and rejections varied by culture but pure self-interest was universally rare).

**Key insight:** Humans have an innate (though culturally modulated) sense of fairness that motivates both cooperation and punishment of violators. This is what makes cooperation sustainable: people will pay a cost to punish cheaters, even when punishment does not benefit them directly (altruistic punishment: Fehr and Gachter, 2002).

**Design implication:** Systems perceived as fair elicit cooperation; systems perceived as unfair elicit sabotage, disengagement, and exit. Transparency in reward allocation, proportional contribution-to-benefit relationships, and visible sanctions for violators all leverage this drive. The fairness instinct is the strongest natural hedge against free-riding and rent-seeking -- if the system activates it.

### 3. Desire for Meaning and Purpose

**Research basis:** Deci and Ryan's (1985, 2000) **self-determination theory** identifies autonomy, competence, and relatedness as fundamental human needs. Pink (2009, *Drive*) popularized the research showing that intrinsic motivation (purpose, mastery, autonomy) outperforms extrinsic motivation (money, titles) for complex, creative work. Frankl (1946, *Man's Search for Meaning*) on the human need for purpose as a survival mechanism.

**Key insight:** People will contribute extraordinary effort for work they find meaningful, even without material reward. Open-source contributors, Wikipedia editors, volunteer firefighters -- intrinsic motivation is a real and powerful force when conditions support it.

**Design implication:** Systems that connect individual work to meaningful outcomes, provide autonomy in execution, and create opportunities for mastery can harness intrinsic motivation. This is the positive counterpart to the free-rider problem: if meaning is the reward, free-riding is self-punishing (you miss the meaning).

### 4. Reputation Concern

**Research basis:** Nowak and Sigmund (1998, 2005) on **indirect reciprocity**: cooperation evolves when reputation information circulates. "I cooperate with you not because you helped me but because you helped others and I know about it." This is the evolutionary basis of reputation as a cooperation-sustaining mechanism.

Milinski, Semmann, and Krambeck (2002) experimentally demonstrated that people cooperate more when their reputation is at stake. Fehr and Fischbacher (2003) showed that reputation effects sustain cooperation even in large groups where direct reciprocity is impossible.

**Key insight:** Reputation concern is the mechanism that scales cooperation beyond Dunbar's number. In small groups, direct reciprocity maintains cooperation. In large groups, reputation serves the same function -- if the reputation system is trustworthy.

**Design implication:** Transparent, hard-to-game reputation systems are the most important positive-tendency hedge. They harness status-seeking (redirect it toward contribution), deter free-riding (visible shirking damages reputation), and sustain cooperation at scale. This is why open-source works: GitHub contribution history is a reputation system that makes cooperation visible.

### 5. Prosocial Punishment (Willingness to Enforce Norms)

**Research basis:** Fehr and Gachter (2002) on altruistic punishment: people will pay a personal cost to punish defectors, even in one-shot games where there is no future benefit. This is not revenge (which is self-serving) but norm enforcement -- a willingness to bear cost to maintain the cooperative system.

Boyd, Gintis, Bowles, and Richerson (2003) modeled how prosocial punishment enables large-scale cooperation: even a small fraction of punishers in a population can stabilize cooperation.

**Key insight:** Humans are not just conditional cooperators; they are willing norm enforcers. This is the natural immune system against defection. But it requires the system to make defection visible and to make punishment possible and legitimate.

**Design implication:** Graduated sanctions (Ostrom's design principle), transparent rule enforcement, and legitimate authority to sanction -- these all activate the natural willingness to enforce norms. The hedge against self-serving punishment (punishing out-group or competitors rather than genuine defectors) is transparency and proportionality.

### 6. Teaching Instinct / Knowledge Sharing

**Research basis:** Csibra and Gergely (2011) on **natural pedagogy**: humans have an evolved capacity and motivation to teach. This is relatively unique among species -- most social learning is observational, but humans actively instruct. Tomasello (1999, *The Cultural Origins of Human Cognition*) argues that shared intentionality and active teaching are the foundation of cumulative culture.

**Key insight:** Humans have a drive to share knowledge, not just hoard it. The information-hoarding tendency is real, but it competes with a teaching instinct that is activated by social recognition, perceived learner receptiveness, and absence of competitive threat.

**Design implication:** Systems that make knowledge sharing safe (no competitive disadvantage), recognized (reputation gains from teaching), and effective (learners visibly benefit) activate the teaching instinct. This directly counteracts information hoarding.

---

## Part F: Summary -- The Refined Taxonomy

### Core Negative Tendencies (Hedge Against)

| # | Tendency | Root Drive | Distinctness | Tier |
|---|----------|-----------|-------------|------|
| 1 | Power-seeking | Resource acquisition | High | 1 |
| 2 | Herd mentality | Cognitive economy | High | 3 |
| 3 | Short-term bias | Cognitive economy | High | 1 |
| 4 | Free-riding | Resource acquisition (defection) | High | 2 |
| 5 | Tribalism | Threat avoidance | High | 2 |
| 6 | Rent-seeking | Composite (power + loss aversion) | Medium (composite) | 3 |
| 7 | Status-seeking | Resource acquisition | Medium (overlaps power) | 3 |
| 8 | Loss aversion | Threat avoidance | High | 2 |
| 9 | Information hoarding | Instrumental (power/threat) | Medium (instrumental) | 3 |
| 10 | Self-deception | Cognitive economy (meta) | High (meta-level) | 1 |
| 11 | Confirmation bias | Cognitive economy | Medium (overlaps self-deception) | 3 |
| 12 | Diffusion of responsibility | Threat avoidance | High | 3 |
| 13 | Overconfidence | Cognitive economy | High | 3 |
| 14 | Envy / Spite | Resource acquisition (relative) | High | 3 |
| 15 | Moral hazard | Resource acquisition (externalized) | High | 2 |
| 16 | Empire-building | Resource acquisition + Status | Medium (composite) | 3 |

### Core Positive Tendencies (Harness)

| # | Tendency | Design Leverage |
|---|----------|----------------|
| P1 | Reciprocity | Make cooperation visible and trackable |
| P2 | Fairness instinct | Ensure transparent, proportional reward systems |
| P3 | Desire for meaning | Connect work to impact, provide autonomy |
| P4 | Reputation concern | Build trustworthy, hard-to-game reputation systems |
| P5 | Prosocial punishment | Enable and legitimize graduated sanctions |
| P6 | Teaching instinct | Make knowledge sharing safe and recognized |

### The Design Equation

The organizational design challenge, restated with this taxonomy:

> Build a system where the **positive tendencies** (reciprocity, fairness, meaning, reputation, norm enforcement, teaching) are systematically activated, while the **negative tendencies** (power-seeking, herd mentality, short-term bias, free-riding, tribalism, rent-seeking, status-seeking, loss aversion, information hoarding, self-deception, confirmation bias, diffusion of responsibility, overconfidence, envy, moral hazard, empire-building) are systematically hedged -- and where the hedges themselves are resistant to capture by the very tendencies they constrain.

The last clause is the hardest part. It is also what makes AI governance interesting: an AI hedge is not subject to the human tendencies it is designed to constrain (though it introduces different failure modes -- alignment problems, training bias, and the risk of AI capture by human power-seekers who control the AI).

---

## Key Sources Referenced

### Behavioral Economics
- Kahneman, D. (2011). *Thinking, Fast and Slow*
- Kahneman, D. & Tversky, A. (1979). Prospect theory: An analysis of decision under risk. *Econometrica*
- Thaler, R. (1980). Toward a positive theory of consumer choice. *J. Economic Behavior & Organization*
- Ainslie, G. (2001). *Breakdown of Will*
- Laibson, D. (1997). Golden eggs and hyperbolic discounting. *Quarterly J. Economics*

### Evolutionary Psychology
- Trivers, R. (1971). The evolution of reciprocal altruism. *Quarterly Review of Biology*
- Trivers, R. (2011). *The Folly of Fools: The Logic of Deceit and Self-Deception in Human Life*
- Cosmides, L. & Tooby, J. (1992). Cognitive adaptations for social exchange. *The Adapted Mind*
- Buss, D. (2005). *The Handbook of Evolutionary Psychology*
- Dunbar, R. (1996). *Grooming, Gossip, and the Evolution of Language*
- Henrich, J. (2016). *The Secret of Our Success*
- Henrich, J. & Gil-White, F. (2001). The evolution of prestige. *Evolution and Human Behavior*

### Social Psychology
- Asch, S. (1956). Studies of independence and conformity. *Psychological Monographs*
- Milgram, S. (1963). Behavioral study of obedience. *J. Abnormal and Social Psychology*
- Zimbardo, P. (2007). *The Lucifer Effect*
- Tajfel, H. et al. (1971). Social categorization and intergroup behaviour. *European J. Social Psychology*
- Janis, I. (1972). *Victims of Groupthink*
- Festinger, L. (1957). *A Theory of Cognitive Dissonance*
- Haidt, J. (2012). *The Righteous Mind: Why Good People Are Divided by Politics and Religion*
- Darley, J. & Latane, B. (1968). Bystander intervention in emergencies. *J. Personality and Social Psychology*

### Game Theory and Cooperation
- Axelrod, R. (1984). *The Evolution of Cooperation*
- Olson, M. (1965). *The Logic of Collective Action*
- Fehr, E. & Gachter, S. (2002). Altruistic punishment in humans. *Nature*
- Fehr, E. & Schmidt, K. (1999). A theory of fairness, competition, and cooperation. *Quarterly J. Economics*
- Nowak, M. & Sigmund, K. (2005). Evolution of indirect reciprocity. *Nature*
- Ostrom, E. (1990). *Governing the Commons*
- Boyd, R. et al. (2003). The evolution of altruistic punishment. *PNAS*

### Organizational Theory and Economics
- Coase, R. (1937). The nature of the firm. *Economica*
- Jensen, M. & Meckling, W. (1976). Theory of the firm. *J. Financial Economics*
- Bebchuk, L. & Fried, J. (2004). *Pay Without Performance*
- Christensen, C. (1997). *The Innovator's Dilemma*
- Tullock, G. (1967). The welfare costs of tariffs, monopolies, and theft. *Economic Inquiry*
- Freeman, J. (1972). The tyranny of structurelessness. *Berkeley Journal of Sociology*
- Niskanen, W. (1971). *Bureaucracy and Representative Government*
- DiMaggio, P. & Powell, W. (1983). The iron cage revisited. *American Sociological Review*

### Primate Behavior and Hierarchy
- de Waal, F. (1982). *Chimpanzee Politics*
- Sapolsky, R. (2004). *Why Zebras Don't Get Ulcers*
- Marmot, M. (2004). *The Status Syndrome*

### Motivation and Meaning
- Deci, E. & Ryan, R. (2000). Self-determination theory. *American Psychologist*
- Pink, D. (2009). *Drive*
- Frankl, V. (1946). *Man's Search for Meaning*
