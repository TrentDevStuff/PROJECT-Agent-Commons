---
type: effort
project: agent-commons
effort_id: EFFORT-Brainstorming-Research
status: completed
priority: high
created: 2026-02-12T19:00:00Z
updated: 2026-02-13T04:00:00Z
linked_goal: G12.1
owner: Trent Peterson
progress: 100%
---

# EFFORT: Brainstorming & Research

## Purpose

Deep research and brainstorming to explore all aspects of the Agent Commons concept, justify and clarify the project through research, and explore implications.

**Core Impetus:**
> Everything will change with the introduction of AI. How can we steer that change to make a better world?
>
> This is the very pith of the idea—all else might change around it. What we have described so far is just one manifestation of what the world might be in that future. There may be other ways, very different from this, so we will keep that in mind.

## Research Areas

This effort maintains these as a tracked research list:

### 1. Problems with Organizational Structures

How to avoid the failures of:

- [x] **Democracy** — Mob-ocracy, tyranny of the majority, short-termism
  - Research examples of democratic failure modes
  - Study how AI could mitigate these issues
  - Analyze when democracy works and when it fails
  - **COMPLETED:** See `01-organizational-failures/DEMOCRACY.md`

- [x] **Socialism** — Central planning failures, free-rider problem, innovation stagnation
  - Research historical socialist experiments
  - Understand the free-rider problem and potential solutions
  - Study innovation incentives in socialist systems
  - **COMPLETED:** See `01-organizational-failures/SOCIALISM.md`

- [x] **Corporatism** — Hierarchy, exploitation, rent-seeking, C-suite extraction, inertia
  - Analyze how corporate structures break down under their own weight
  - Study C-suite compensation vs. value creation
  - Research organizational inertia and resistance to change
  - **COMPLETED:** See `01-organizational-failures/CORPORATISM.md`

- [x] **Other Models** — Cooperatives, kibbutzim, holacracy, etc.
  - Worker cooperatives (Mondragon, etc.)
  - Israeli kibbutzim (successes and failures)
  - Holacracy and other flat organizational models
  - What worked? What failed? Why?
  - **COMPLETED:** See `01-organizational-failures/ALTERNATIVE-MODELS.md`

### 2. AI-Driven Societal Changes

The democratization of knowledge and skill:

- [x] **Corporate Structure Breakdown**
  - How does AI level the playing field?
  - What happens when small teams have expert-level capability?
  - How does corporate inertia become a fatal weakness?
  - **COMPLETED:** See `02-ai-driven-change/CORPORATE-BREAKDOWN.md`

- [x] **Self-Organizing Teams**
  - How can small teams fill the gap left by corporations?
  - What organizational patterns emerge naturally?
  - Building on gig economy (Upwork, Fiverr) but going further
  - **COMPLETED:** See `02-ai-driven-change/SELF-ORGANIZING-TEAMS.md`

- [x] **Knowledge Democratization**
  - What happens when anyone can access expert-level capability through AI?
  - The end of knowledge hoarding as competitive advantage
  - How does this change power dynamics?
  - **COMPLETED:** See `02-ai-driven-change/KNOWLEDGE-DEMOCRATIZATION.md`

- [x] **Economic Implications**
  - How do productivity gains get distributed?
  - What happens to employment and income?
  - New economic models needed?
  - **COMPLETED:** See `02-ai-driven-change/ECONOMIC-IMPLICATIONS.md`

### 3. Similar Models and Precedents

What already exists to build upon:

- [x] **Open-Source Movement**
  - Governance models (Linux Foundation, Apache, etc.)
  - Contribution tracking and reputation systems
  - Sustainability challenges (who pays?)
  - Success patterns and failure modes
  - **COMPLETED:** See `03-models-and-precedents/OPEN-SOURCE.md`

- [x] **GitHub as Organizational Infrastructure**
  - Issues as work tracking
  - Pull requests as contribution model
  - Forks as organizational evolution
  - Stars as reputation system
  - How could this extend to non-code work?
  - **COMPLETED:** See `03-models-and-precedents/GITHUB-INFRASTRUCTURE.md`

- [x] **DAOs (Decentralized Autonomous Organizations)**
  - What worked in DAO experiments?
  - What failed spectacularly?
  - Why did token-voting lead to plutocracy?
  - Can AI governance avoid these pitfalls?
  - **COMPLETED:** See `03-models-and-precedents/DAOS.md`

- [x] **Platform Cooperatives**
  - Examples: Stocksy, Resonate, Fairmondo
  - Governance structures
  - Member ownership vs. platform ownership
  - Successes and challenges
  - **COMPLETED:** See `03-models-and-precedents/PLATFORM-COOPERATIVES.md`

- [x] **Prediction Markets & Mechanism Design**
  - How can we design systems that align incentives?
  - What can we learn from prediction markets?
  - Futarchy (voting on values, betting on beliefs)
  - **COMPLETED:** See `03-models-and-precedents/PREDICTION-MARKETS-MECHANISM-DESIGN.md`

- [x] **Academic Research**
  - AI-governed organizations
  - Multi-agent systems
  - Game theory and mechanism design
  - Organizational economics
  - **COMPLETED:** See `03-models-and-precedents/ACADEMIC-THEORETICAL-FRAMEWORKS.md`

## Success Criteria

- [x] Comprehensive understanding of organizational failure modes — See Area 1: 6 documents covering democracy, socialism, corporatism, alternative models, human nature taxonomy, and cross-model synthesis
- [x] Clear articulation of how AI changes the landscape — See Area 2: 4 documents covering corporate breakdown, self-organizing teams, knowledge democratization, and economic implications
- [x] Documented precedents with analysis of successes/failures — See Area 3: 6 documents covering open-source, GitHub, DAOs, platform cooperatives, mechanism design, and academic frameworks
- [x] Multiple potential organizational models beyond Agent Commons — See [[CROSS-AREA-SYNTHESIS]] Section 5: three alternative models (Federated Micro-Enterprises, AI-Augmented Steward Ownership, Public AI Infrastructure) plus hybrid scenario
- [x] Identified key risks and how to hedge against them — See [[CROSS-AREA-SYNTHESIS]] Sections 4, 6: 5 specific gaps, 5 hardest problems ranked, 5 falsification conditions, 8 arguments against feasibility
- [x] Research findings documented for future reference — 16 research documents + 3 RESEARCH.md guides + 1 cross-area synthesis, 300+ academic sources, 11,000+ lines of documented research

## Progress Log

### 2026-02-13: Cross-Area Synthesis Completed
- Created `CROSS-AREA-SYNTHESIS.md` (~900 lines)
- Synthesized all 16 source documents across 3 research areas into unified assessment
- Progress updated from 70% to 85%

**Section 1 - The Convergence:**
- Identified how all 3 research areas independently arrive at the same structural conclusion: corporate form mismatched with AI-era environment, technology enables different coordination, governance is the hardest problem
- Documented 3 reinforcements (hedge-and-crack validated by precedents, transaction costs explain accelerating failure, mechanism design implements design principles), 3 contradictions (small-team optimism vs. hierarchy inevitability, impossibility results vs. design ambitions, knowledge democratization vs. power-law concentration), and 3 productive tensions

**Section 2 - Human Nature x AI Matrix:**
- Mapped all 16 negative tendencies and 6 positive tendencies against AI's effect
- 5 tendencies where AI genuinely helps (information hoarding, short-term bias, free-riding, herd mentality, rent-seeking)
- 5 tendencies where AI makes things worse (power-seeking via AI capture, self-deception via AI rationalization, tribalism via algorithmic amplification, status-seeking via Goodhart's Law, moral hazard via diffusion of responsibility)
- 3 tendencies with genuinely uncertain AI effects (loss aversion, overconfidence, envy/spite)

**Section 3 - Unified Design Specification:**
- Merged Area 1's 10 design principles, Area 2's 8 infrastructure layers, Area 3's transferable mechanisms, and 6-layer incentive architecture into 6-layer unified framework
- Identified minimum viable hedge set: small groups, transparent contribution tracking, credible exit, proportional bounded rewards, plural adversarial monitoring, automatic renewal

**Section 4 - Agent Commons Evaluation:**
- What research supports: Coasian logic, contribution-based economics, forking as governance, code-shaped work gap as design space
- What research challenges: governance harder than acknowledged, sustainability unsolved, cold-start has killed every comparable attempt, reputation gaming is arms race
- 5 specific gaps: no AI separation of powers, no Sybil resistance, no legal framework, no non-code contribution tracking, no meaning-of-work answer

**Section 5 - Alternative Models:**
- Model A: Federated Micro-Enterprises (Agent Commons variant) -- best for knowledge work
- Model B: AI-Augmented Steward-Owned Enterprises (Bosch/Patagonia model) -- best for existing companies, manufacturing, regulated industries
- Model C: Public AI Infrastructure with Contribution Dividends (Alaska Fund model) -- best for infrastructure layer
- Hybrid reality: all three needed for different segments

**Section 6 - Honest Assessment:**
- 5 genuinely novel elements identified
- 5 hardest problems ranked by confidence (recursive AI governance, Sybil resistance, sustainability economics, non-code tracking, legitimacy over time)
- 5 falsification conditions (AI plateau, human nature not primary cause, AI governance rejected on principle, concentration structurally inevitable, transition costs exceed benefits)
- Integrated 6-FOR/8-AGAINST with cross-area evidence: FOR arguments strengthened by technology evidence, AGAINST arguments strengthened by human nature evidence

**Section 7 - Research Gaps & Next Steps:**
- 5 critical experiments designed (AI governance legitimacy, reputation gaming resistance, Forg formation dynamics, Constitutional AI for governance, sustainability economics)
- 4 theoretical work items (formal game model, multi-principal alignment, power-law bounding, non-code value attribution)
- 3 simulation tracks (agent-based modeling with human nature, evolutionary dynamics, stress testing)
- 5-phase sequencing proposed: theoretical (3-6mo) -> simulation (3-6mo) -> small experiment (12-18mo) -> iteration -> careful scaling

### 2026-02-12: Models & Precedents Threads 3.4, 3.5, 3.6 Completed
- Created `03-models-and-precedents/PLATFORM-COOPERATIVES.md` (~700 lines)
- Created `03-models-and-precedents/PREDICTION-MARKETS-MECHANISM-DESIGN.md` (~700 lines)
- Created `03-models-and-precedents/ACADEMIC-THEORETICAL-FRAMEWORKS.md` (~650 lines)
- Updated `03-models-and-precedents/RESEARCH.md` with findings summaries and completion status
- **Area 3 is now fully completed (all 6 threads done)**

**Thread 3.4 - Platform Cooperatives:**
- 7 deep case studies: Stocksy United (stock photography cooperative -- 50-75% photographer royalties vs 15-25% at incumbents, ~1,500-2,000 curated photographers, $10-15M revenue, self-sustaining since 2013 without VC, founder Livingstone's iStockphoto credibility as bootstrap mechanism), Resonate (music streaming cooperative -- stream-to-own exponential pricing model, multi-stakeholder governance with artist/listener/worker classes, failed to achieve scale due to catalog licensing, habit lock-in, and technology development burden), Fairmondo (German marketplace cooperative -- EUR 400K crowdfund, Genossenschaft structure, never achieved critical mass against Amazon, effectively stagnated), Up & Go (NYC cleaning cooperative -- 95% of revenue to workers vs 70-85% on conventional platforms, federation of existing cooperatives, low hundreds of workers, grant-dependent, social infrastructure more important than technology), Drivers Cooperative (NYC ride-hailing co-op -- 15% take rate vs Uber's 25-40%, several thousand members, competitive on driver economics but struggling with rider acquisition and supply density), Aragon (DAO governance tooling -- thousands of DAOs created but most inactive, Aragon's own governance crisis in 2023 as irony, on-chain governance adds friction most organizations don't need), Eva (Montreal ride-hailing co-op -- same structural challenges as TDC, Quebec's cooperative-friendly law not sufficient)
- The Competitive Challenge: Trebor Scholz's analysis of VC vs. cooperative asymmetry (VC burns capital for growth, co-ops must self-sustain from day one). Chicken-and-egg problem in platform markets -- solved only by leveraging existing communities. Network effects create structural lock-in. Data as competitive advantage -- AI and open-source models as partial equalizer
- Technology as Equalizer: AI narrows technology gap but does not solve capital, network-effect, or marketing gaps. CoopCycle (delivery), Decidim (democracy), Loomio (governance) as shared infrastructure. Platform cooperative toolkit vision: technology + governance + federation layers
- Governance at Scale: One-member-one-vote limitations (voter fatigue, information asymmetry, speed, participation scale). Professional management capture (Webbs' prediction partially validated). Sociocracy/consent-based governance (Endenburg) as alternative -- circle structure maps to Forgs, consent faster than consensus but slower than hierarchy, limited to hundreds of members. Scale ceiling: no platform cooperative exceeds low thousands of active participants
- Agent Commons Comparison: 8-dimension comparison table (membership, ownership, rewards, governance, exit, capital, technology, decision-making). Key borrowings: value distribution, no outside equity, non-capital governance, open participation. Key differences: no formal membership, AI governance, forkability, contribution-based rewards. 5 cooperative warnings for Agent Commons: capital problem, network effects, governance legitimacy, technology not bottleneck, take-rate sustainability
- 30+ sources cited (Scholz, Schneider, Parker/Van Alstyne/Choudary, Webb, Endenburg, Rau/Koch-Gonzalez, CoopCycle/Decidim/Loomio)

**Thread 3.5 - Prediction Markets and Mechanism Design:**
- Prediction markets state of the art: Polymarket (blockchain-based, largest real-money market, 2024 election accuracy notable, CFTC settlement), Metaculus (reputation-based, logarithmic proper scoring rule, COVID forecasts competitive with institutional), Manifold Markets (play-money, surprisingly good accuracy per Wolfers/Zitzewitz research on play vs real money), Kalshi (first CFTC-regulated US prediction market, event contracts), internal corporate markets at Google/HP/Intel (outperform official forecasts for sales, product dates)
- When prediction markets work (5 conditions) vs. fail (6 failure modes): well-defined resolution, liquid/diverse markets, skin in game, independent judgment, non-reflexive events // thin markets, manipulation, ambiguity, reflexivity, long horizons, identity-driven betting
- Futarchy deep analysis: Hanson's "vote on values, bet on beliefs" formulated as worked example with organizational decision-making. Five criticisms: manipulation risk, measurable welfare function definition, thin market problem, conditional market complexity, time horizon. Real-world status: no full implementation, limited DAO experiments, mixed laboratory results. AI-enhanced futarchy proposed: human QV on values, AI estimation of outcomes, prediction markets as check on AI
- Quadratic Voting: Weyl/Posner from *Radical Markets* -- mathematical proof of optimality (marginal cost = marginal social cost). Prevents plutocracy and tyranny of indifferent majority. Colorado legislature, Taiwan digital democracy experiments
- Quadratic Funding: Buterin/Hitzig/Weyl 2019 *Management Science* paper. Formula: square of sum of square roots. Worked example showing 100x1 vs 1x100 differential. Gitcoin Grants as largest experiment ($60M+ distributed). Gaming and Sybil resistance as constant challenges
- Sybil Resistance: the core unsolved problem for any quadratic mechanism. Proof of Humanity, BrightID, Gitcoin Passport, Worldcoin analyzed. Fundamental tension: Sybil resistance requires proving unique humanness, which conflicts with pseudonymous/anonymous participation
- Mechanism Design Theory: VCG mechanisms (truth-telling as optimal strategy, Vickrey auction as simplest case, limitations: budget balance, collusion, complexity). Auction theory (Milgrom/Wilson 2020 Nobel, spectrum auctions $200B+, Google AdWords). Matching markets (Roth/Shapley 2012 Nobel, medical residency, kidney exchange, school choice -- directly applicable to Forg formation). Myerson's revelation principle (truth-telling mechanisms always exist; practical constraint: budget balance + collusion resistance + computation). Impossibility results (Arrow, Gibbard-Satterthwaite, Myerson-Satterthwaite) as mathematical proof that trade-offs are inevitable
- Reputation Systems: eBay (pioneering but 99.1% positive inflation, retaliation dynamics, gaming), Stack Overflow (gamification harnesses status-seeking, rewards quantity over quality, creates entrenched elite, Goodhart's Law), Uber/Lyft (4.6-star death zone, racial/gender bias documented, platform controls workers through ratings), Amazon (30-40% fake reviews in some categories, arms race between detection and generation), academic peer review (expert evaluation valuable but slow, gatekeeping, fraud detection poor, replication crisis). Six properties of robust reputation systems; five failure modes
- AI as Mechanism Designer: dynamic incentive adjustment concept, AMMs as precedent (Uniswap $100B+ in trades), surge pricing as dynamic mechanism. MARL and mechanism discovery (Duetting et al./Google Research, Conitzer/Duke, Baumann et al.). Alignment challenge: who ensures AI-designed incentives serve humans?
- Six-layer incentive architecture proposed for Agent Commons: constitutional values (QV), policy selection (prediction-market-informed QV), resource allocation (QF), contribution valuation (multi-dimensional AI-enhanced reputation), forg formation (matching markets), mechanism monitoring (adversarial AI + human oversight)
- 40+ sources cited (Hanson, Weyl/Posner, Buterin/Hitzig/Weyl, Hurwicz, Myerson, Vickrey, Milgrom, Roth, Arrow, Gibbard, Satterthwaite, Resnick/Zeckhauser, Duetting et al., Conitzer, Leibo et al.)

**Thread 3.6 - Academic and Theoretical Frameworks:**
- Multi-Agent Systems: MAS as the CS formalization of organizational coordination without central control. Agent autonomy, coordination mechanisms (communication, negotiation, norms, markets), coalition formation. BDI architecture (Rao/Georgeff, building on Bratman) -- beliefs/desires/intentions map to organizational behavior; self-deception distorts beliefs, desire conflicts drive politics, intention commitment causes inertia. Craig Reynolds' Boids as emergent behavior demonstration -- simple rules produce complex adaptive flocking. Contract Net Protocol (Smith 1980) as Forg formation analogue. Wooldridge finding: institutional structure matters more than agent quality. Sycara finding: negotiation protocol structure significantly affects outcome quality and fairness. Sandholm finding: computational mechanism design outperforms general-purpose theoretical mechanisms
- Game Theory: Nash equilibria as stable but potentially suboptimal resting points -- Prisoner's Dilemma as organizational analogy. Multiple equilibria and focal points (Schelling) -- culture/norms as coordination to good equilibria. Shapley value for fair contribution attribution -- theoretically optimal but computationally hard, counterfactuals unobservable, dynamic contributions problematic. AI-assisted Shapley estimation proposed. Evolutionary game theory -- Axelrod's tournament: Tit-for-Tat wins (nice, retaliatory, forgiving, clear). Four conditions for cooperation: repeated interaction, recognizable agents, low probability of ending, punishment capacity -- implies long-term forgs, cross-forg reputation, persistent identity, bounded exit costs. Public goods games: initial cooperation high but decays, communication helps, punishment sustains cooperation (Fehr/Gachter), reputation sustains cooperation, group size hurts, heterogeneity complicates. Folk Theorem: cooperation sustainable in repeated games -- portfolio of long-term and short-term forgs recommended
- Organizational Economics: Williamson's TCE (asset specificity, bounded rationality, opportunism) -- AI reduces bounded rationality and monitoring costs, but may INCREASE asset specificity. Hart's incomplete contracts -- residual control rights as the essence of ownership, whoever controls AI judges holds de facto residual control. Property rights theory -- clear rights reduce conflict and increase investment, Agent Commons must define contribution ownership and forkability rights. Alchian/Demsetz team production -- firms exist because joint output cannot be separated into individual contributions; AI monitoring potentially solves this by tracking contributions at finer granularity, but creative contributions remain hard to measure, and monitoring may crowd out intrinsic motivation (Gneezy/Rustichini)
- AI Alignment and Governance: Russell's framing (beneficial, uncertain about preferences, correctable). MIRI's mathematical foundations (proxy misalignment). Anthropic's Constitutional AI (principles rather than rules) -- directly applicable to organizational AI governance. Multi-principal alignment as the Agent Commons-specific alignment problem -- connects to Arrow's impossibility (no aggregation rule satisfies all properties). Value alignment aggregation: utilitarian vs. egalitarian vs. proportional vs. quadratic approaches -- each is a political choice disguised as technical. Cooperative AI research (Dafoe et al.) on multi-agent alignment. AI safety insights for organizational design: specification gaming = Goodhart's Law, corrigibility requires ongoing engagement, distributional shift breaks fixed governance
- Complexity Theory: Complex Adaptive Systems (Santa Fe Institute) -- organizations as CAS with adaptation, self-organization, nonlinearity, co-evolution. Kauffman's NK models and edge of chaos -- too much structure produces rigidity (corporate bureaucracy), too little produces chaos (failed DAOs), intermediate K maximizes adaptation. Emergence: you can design rules but not outcomes -- both promise (emergent innovation) and risk (emergent pathologies). Power laws from preferential attachment (Barabasi/Albert) -- predicts inequality will emerge regardless of design, must be actively bounded. Resilience theory (Holling, Walker/Salt): redundancy, modularity, diversity -- all reduce efficiency but increase resilience
- **The Meta-Question synthesized:** 6 theoretical arguments FOR feasibility (transaction cost reduction, mechanism design tools, cooperative equilibria, self-organization at edge of chaos, AI monitoring, Ostrom's principles) vs. 8 arguments AGAINST (impossibility results, power-law dynamics, multi-principal alignment unsolved, asset specificity increase, incomplete contracts leave residual control unresolved, emergent pathologies, free-riding scales, purpose fades). 5 genuinely uncertain questions identified (AI fairness perception, AI governance legitimacy, edge-of-chaos location, reputation gaming resistance, effective scale)
- Research agenda proposed: empirical (small-scale experiments, mechanism comparison, AI fairness perception, scale testing), theoretical (formal Agent Commons game model, optimal forg mechanism design, AI governance alignment proofs, power-law bounding), simulation (agent-based modeling with human-nature tendencies, evolutionary dynamics, stress testing)
- 50+ sources cited (Wooldridge, Smith, Rao/Georgeff, Reynolds, Sycara, Sandholm, Nash, Shapley, Axelrod, Fehr/Gachter, Schelling, Williamson, Hart, Alchian/Demsetz, Coase, Russell, Anthropic, Dafoe et al., Conitzer, Kauffman, Holland, Arthur, Barabasi/Albert, Holling, Arrow, Sen)

### 2026-02-12: Models & Precedents Threads 3.1, 3.2, 3.3 Completed
- Created `03-models-and-precedents/OPEN-SOURCE.md` (~850 lines)
- Created `03-models-and-precedents/GITHUB-INFRASTRUCTURE.md` (~550 lines)
- Created `03-models-and-precedents/DAOS.md` (~750 lines)

**Thread 3.1 - Open-Source Movement:**
- Six governance models compared in depth: Linux Foundation (corporate-backed, separation of financial/technical influence, 75-85% of kernel contributions from corporate employees), Apache Software Foundation (formalized meritocracy with 5 tiers, "community over code" principle, lazy consensus, 3 +1 vote release requirement), Debian (democratic model with Condorcet voting, Social Contract as constitutional constraint, systemd controversy as case study), Rust (RFC process, team-based governance, 2021-2023 governance crisis -- Core Team accumulation of power, Moderation Team resignation, Foundation trademark controversy, successful reform to Leadership Council), Python (BDFL model, Van Rossum burnout/resignation over PEP 572, smooth transition to Steering Council), Node.js/io.js (fork-and-reunification as governance correction in 8 months)
- Governance comparison table across 7 dimensions: decision speed, capture resistance, contributor satisfaction, scalability, legitimacy, fork threat effectiveness, sustainability
- Contribution and reputation analysis: transparent contribution tracking as open source's greatest innovation; reputation enables employment, influence, speaking invitations; maintainer bottleneck documented (median project 1-2 people); contribution measurement beyond commits remains unsolved; open-source credentialing partially disrupting traditional credentials but with socioeconomic bias
- **Sustainability crisis -- the critical precedent for Agent Commons:** Log4j incident (2021, CVSS 10.0, maintained by volunteers, companies contributing nothing), core-js maintainer ($250/month for library used by 50% of websites, imprisonment, financial distress), xz utils backdoor (2024, sustainability crisis weaponized as attack vector, social engineering of burned-out maintainer). Models that partially work: Red Hat/services, open-core/source-available licensing, GitHub Sponsors/Open Collective/Tidelift (but median <$1,000/year), corporate OSPOs. Models that don't work: donations alone, "exposure", hoping corporations contribute. Harvard study: open-source value >$8.8 trillion, total funding low hundreds of millions
- Forking as governance: 7 major forks analyzed (LibreOffice, MariaDB, io.js, Devuan, Nextcloud, Jenkins). Corporate capture most common trigger. ~30% forks become more successful than parent, ~40% survive alongside, ~30% decline. Hirschman's Exit/Voice/Loyalty framework applied. Critical conditions for forking-as-governance: work product must be portable, reputation must be portable, community must be informed
- Limits of open source: structurally weak at design/UX (opinionated, requires funded professionals), marketing/distribution, user research, long-term maintenance (status-seeking rewards creation over maintenance). Self-organizing technical communities excel at production but cannot sustain themselves financially
- 7 direct borrowings identified for Agent Commons; 7 unsolved problems that Agent Commons must address

**Thread 3.2 - GitHub as Organizational Infrastructure:**
- Git primitives analyzed as organizational mechanisms: branching (parallel workstreams without interference, breaks down for non-mergeable outputs), merging (integration with explicit conflict resolution, breaks down for strategy/design), pull requests (proposal-review-integration workflow -- combines 6 steps no other mechanism provides, breaks down for subjective quality), issues (open work tracking, breaks down with volume), forks (exit without loss, organizational mitosis), version control as organizational memory (attribution, recoverability, atomicity)
- Contribution visibility: GitHub contribution graph vs. corporate performance review compared across 8 dimensions. "Green squares" gaming problem (Goodhart's Law). PR review as highest-quality human-operated QA mechanism
- GitHub-like tools for non-code: Figma (branching, version history, but proprietary/non-forkable), Notion (collaborative but no branching/merging/forking), Linear (git-like work management). Convergence thesis partially supported but tools remain proprietary and incompatible
- "Code-shaped work" bias: Git model systematically privileges measurable, visible, technical, individual work over immeasurable, invisible, social, collective work. Agent Commons must either develop equivalent primitives for non-code work, compensate through weighting, or accept narrow scope
- The decision-making gap: GitHub provides no infrastructure for strategic decisions, resource allocation, governance, or value judgments. This gap IS the design space for Agent Commons
- Microsoft acquisition lesson: infrastructure must be decentralized/interoperable or community becomes structurally dependent on potential future captor

**Thread 3.3 - DAOs (Decentralized Autonomous Organizations):**
- The DAO hack (2016) detailed post-mortem: $150M crowdfund, re-entrancy exploit, $60M drained, "code is law" vs. human judgment crisis, Ethereum hard fork decision. Four lessons: code cannot replace judgment, emergency mechanisms essential, legitimacy from consent not technical purity, forking as ultimate governance mechanism
- **Token-voting plutocracy -- the core DAO failure:** One-token-one-vote recreates shareholder capitalism without regulatory guardrails. Chainalysis data: <1% of holders control >90% of voting power. Voter apathy: 1-10% typical turnout. Whale domination case studies: Uniswap DeFi Education Fund ($25M directed by few whales), Beanstalk flash loan governance attack ($182M drained via "legitimate" governance vote). DAO token voting compared to corporate shareholder voting across 7 dimensions -- substantively the same, in some ways worse
- Successful DAOs analyzed: MakerDAO (clear measurable purpose, professional delegates, governance facilitators, but MKR concentration and Rune Christensen's BDFL-like influence), Gitcoin (quadratic funding innovation, $60M+ distributed, but persistent Sybil challenges), ENS (bounded scope, airdrop-based distribution, steward structure), Uniswap (successful protocol, dysfunctional governance), Nouns DAO (innovative daily auction + ragequit mechanism, but expensive/exclusive)
- **Governance innovations from DAOs -- the most transferable learnings:** Quadratic voting/funding (reduces plutocracy, Gitcoin as real-world experiment), conviction voting (sustained commitment = more weight, 1Hive implementation), liquid delegation (per-issue, instantly revocable), Optimism's bicameral model (Token House for protocol, Citizens' House for values -- explicitly separates financial-stake governance from identity-based governance), reputation-based voting (holy grail but Sybil resistance unsolved without financial stake), optimistic governance (auto-approve unless challenged), futarchy (vote on values, bet on beliefs, MetaDAO experimenting)
- **AI governance vs. token governance -- critical comparison:** AI plausibly solves plutocracy, voter apathy, decision speed, expertise gap. AI may NOT solve power concentration (AI capture), legitimacy, gaming (Goodhart's Law at organizational scale), recursive governance problem. AI governance CREATES new problems: opacity, dependence, value lock-in, concentration of technical power. Constitutional AI as model for encoding organizational values into AI alignment constraints -- but who writes the AI constitution?
- Legal/regulatory: DAO legal status across jurisdictions (Wyoming, Marshall Islands, Switzerland), general partnership default liability, tax ambiguity, securities law risk. Agent Commons faces same issues plus AI governance liability, employment classification, IP ownership, cross-jurisdictional complexity
- 6 DAO mistakes Agent Commons must avoid; 8 DAO innovations Agent Commons should adopt. Honest assessment: AI governance is a different set of tradeoffs, not a solution -- success depends on implementing all 6 requirements from Area 1 synthesis

### 2026-02-12: Knowledge Democratization and Economic Implications Completed (Threads 2.3 & 2.4)
- Created `02-ai-driven-change/KNOWLEDGE-DEMOCRATIZATION.md` (~650 lines)
- Created `02-ai-driven-change/ECONOMIC-IMPLICATIONS.md` (~700 lines)
- Updated `02-ai-driven-change/RESEARCH.md` -- Area 2 now fully completed (all 4 threads done)

**Thread 2.3 - Knowledge Democratization:**
- Profession-by-profession analysis of AI disruption across 7 domains: legal (Harvey AI, CoCounsel, 80-90% of contract review automatable), medical (AI matching specialists in imaging, drug discovery acceleration via AlphaFold), financial (robo-advisors mature, 85% of active managers underperform index), software engineering (46% of GitHub code AI-generated, 55% faster task completion with Copilot), education (AI tutoring promising but ~0.2-0.8 sigma vs Bloom's 2-sigma from human tutoring), creative fields (severe impact on mid-tier professionals, stock illustration declining), consulting (BCG/Harvard study: AI helps "within frontier" tasks 25% faster / 40% higher quality, but HURTS "outside frontier" novel judgment tasks)
- Five candidates for new power base analyzed: capital (AI infrastructure concentration), execution speed (favors small teams), taste/judgment (strongest current candidate but may be temporary), social capital (resistant to automation but also to democratization), attention (already scarce, dystopian incentives)
- Skill-biased technological change: Autor framework disrupted because AI automates NON-routine cognitive tasks for first time. Brynjolfsson study shows AI helps novices 34% vs. experts 0-5% (leveling up effect)
- Matthew Effect analysis: AI adoption correlates with existing privilege (education, income, geography). But technology itself has equalizing properties. Net outcome depends on institutional design
- Photography/painting precedent analyzed for AI creativity question. Key uncertainty: does AI plateau below human creative parity, or eventually exceed it?
- Digital Divide 2.0: three layers (infrastructure, literacy, agency). Language barriers significant -- 75% of internet content in 10 languages
- Education implications: Caplan's signaling argument strengthened by AI. Micro-credentials, portfolios, competency-based assessment emerging
- Seven remaining scarcities identified post-knowledge-democratization

**Thread 2.4 - Economic Implications:**
- Labor share decline documented (65% to 56-58%, 1970-2020) as the baseline AI inherits
- Acemoglu vs. Autor debate analyzed in depth: Acemoglu's "so-so automation" and 0.53-0.66% TFP estimate vs. Autor's "new work" hypothesis and institutional choice argument. Both right about different dimensions
- Current labor market data: no macro job destruction but sector-specific displacement real (Klarna: AI = 700 agents; freelance writing rates down 30-50%; concept art 70% reduced opportunities)
- UBI experiments analyzed: Finland (2017-2018, 2000 recipients, EUR 560/month -- no employment effect, significant wellbeing improvement), Stockton SEED ($500/month -- employment INCREASED from 28% to 40%, <1% spent on alcohol/tobacco), GiveDirectly ($600M+ to 1.5M people across 14 countries -- positive development outcomes)
- Five distribution models compared: UBI, contribution-based (Agent Commons), stakeholder capitalism (Business Roundtable 2019 was empty rhetoric per Bebchuk/Tallarita analysis; codetermination has teeth), public AI dividends (Alaska Permanent Fund as model), and alternatives (profit sharing, UBS, NIT)
- Agent Commons economic model: hybrid value attribution (commits + peer review + market signals + AI quality assessment), 5-8% take rate, progressive distribution with floors and ceilings, tiered services, competition resilience through trust/alignment vs. VC-subsidized pricing
- Winner-take-all dynamics: evidence both ways. Training concentrates, usage democratizes. Open-source AI is strongest countermeasure but insufficient alone
- Commons sustainability via open-source precedent: consulting (Red Hat $3.4B), dual licensing (MongoDB $20B+), SaaS/hosted (GitHub $200M ARR), sponsorship (Wikipedia $150M/yr). Hybrid model most realistic
- Detailed comparison table: Agent Commons vs. Traditional Corp vs. Gig Platform vs. DAO across 7 dimensions
- Five open economic questions identified for further work

### 2026-02-12: AI-Driven Change Threads 2.1 and 2.2 Completed
- Created `02-ai-driven-change/CORPORATE-BREAKDOWN.md` (~750 lines)
- Created `02-ai-driven-change/SELF-ORGANIZING-TEAMS.md` (~750 lines)
- Updated `02-ai-driven-change/RESEARCH.md` with findings summaries

**Thread 2.1 - Corporate Structure Breakdown:**
- Coase's transaction cost framework revisited in detail with Williamson (TCE) and Hart (incomplete contracts) extensions
- AI's impact on each transaction cost type quantified: search costs (70-90% reduction), coordination costs (60-85%), monitoring (50-75%), bargaining (50-70%), asset specificity (30-50%), incomplete contracts (30-50%)
- "1000x engineer" debunked -- honest number is 3-5x, but minimum viable team dropping from ~15 to ~3-5 is structurally significant
- AI-native startup revenue-per-employee data: Midjourney ($5M), ElevenLabs ($1.6M), vs. traditional tech ($200K-$500K)
- Corporate layoffs explicitly tied to AI documented: IBM, Klarna (AI = 700 agents), BT Group, SAP, Chegg, Duolingo, Dropbox, Google, UPS
- Six corporate functions analyzed for unbundling progress: customer service (high), content (high), legal (moderate-high), accounting (high), software development (high), HR (moderate)
- Six domains resistant to disaggregation analyzed: physical manufacturing (strong resistance), regulated industries (moderate), deep capital (very strong), network effects (persistent/strengthening), brand trust (slowly eroding), institutional knowledge (partially eroding)
- "Barbell distribution" hypothesis: very large platforms + very small AI teams, hollowed-out middle
- Corporate inertia analyzed as Christensen's Innovator's Dilemma repeating faster with AI

**Thread 2.2 - Self-Organizing Teams:**
- AI-native startup organizational patterns documented: flat, remote-first, 80-95% technical, AI as "team member"
- Management function decomposed into 9 sub-functions; AI can replace ~60-70% (information processing) but not human relationship or judgment functions
- Vibe coding and non-engineer builders: domain expertise becoming more valuable than technical execution
- Five Forg analogies analyzed in depth: film production crews, consulting project teams, open-source sprints, music industry sessions, emergency response (ICS). Key finding: ALL have hierarchy, even if temporary
- Cross-model analysis table comparing how each handles trust, accountability, quality, payment, IP, formation speed, hierarchy, dissolution
- Trust research: Meyerson/Weick/Kramer "swift trust" in temporary organizations; Bolton/Greiner/Ockenfels reputation gaming; Resnick/Zeckhauser reputation value
- Seven requirements for effective reputation systems identified; no existing system meets all of them
- Scale limits: Dunbar's nested layers (5/15/50/150), Buurtzorg 12-person model, Gore's 150-person plant rule, military squad structure
- Minimum viable organization table for 10 work types
- Seven infrastructure layers for Agent Commons platform specified: Discovery, Coordination, Reputation, Payment, Trust, Legal, Quality, plus Governance
- Honest assessment: hierarchy myth debunked, reputation gap identified, governance as the critical unsolved problem
- 40+ academic sources cited across both documents

### 2026-02-12: Alternative Models Deep Research Completed
- Created `01-organizational-failures/ALTERNATIVE-MODELS.md` (~850 lines)
- Full hedge-and-crack analysis of 5 alternative organizational models through human nature lens
- **Worker Cooperatives / Mondragon:** 7 hedges analyzed (one-member-one-vote, pay ratio caps, democratic management, profit sharing, intercooperation, cooperative bank, education). 7 cracks documented (pay ratio creep 3:1 to 9:1, non-member worker class ~20-30%, Fagor bankruptcy as case study, decision speed deficit, capital constraints, generational commitment decay, informal hierarchy). Additional co-ops examined (Emilia-Romagna, John Lewis, REI, CHCA)
- **Israeli Kibbutzim:** 6 hedges analyzed (communal ownership, equal distribution, role rotation, General Assembly, social pressure, shared ideology). 6 cracks documented with Abramitzky's adverse selection data (high-ability exit 2-3x rate), privatization timeline (75% abandoned collective pay), children's houses controversy, social capital hierarchy, generational free-riding, external market pressure. Religious kibbutzim survival rates analyzed
- **Flat Organizations:** 7 case studies (Zappos/holacracy 18% quit, Valve shadow hierarchy, Morning Star, Gore, Buurtzorg, GitHub, Medium). Jo Freeman's "Tyranny of Structurelessness" as theoretical framework. Evidence that flat orgs may have MORE inequality through invisible hierarchy
- **Ostrom's Commons Governance:** All 8 design principles analyzed as hedges against specific human tendencies. Scale, heterogeneity, speed-of-change limitations assessed. Digital commons (Wikipedia, Linux) evaluated. Direct connection to Agent Commons concept mapped against all 8 principles
- **Guild Systems:** 4 hedges and 4 cracks. Historical precedent for self-governance becoming extractive. Modern echoes in professional licensing
- **Cross-Model Synthesis:** 6 hedges that work across models identified (small groups, transparency, shared purpose, proportional reward, market discipline, democratic governance at appropriate scale). 4 universal cracks identified (power-seeking always finds a channel, free-riding scales, ideology fades, markets erode equality). 8 design requirements for any new organizational model derived. 5 unsolved problems identified
- 50+ academic sources cited (Kasmir, Abramitzky, Freeman, Ostrom, Ogilvie, Perotin, Wright, and many others)

### 2026-02-12: Cross-Model Synthesis Completed
- Created `01-organizational-failures/SYNTHESIS.md` (~850 lines)
- Thesis validated across all four organizational models with high confidence
- Identified master compounding cycle: self-deception -> governance capture -> feedback destruction -> friction accumulation -> crisis
- Ranked 10 human-nature tendencies by universality and designability
- Self-deception, power-seeking, and tribalism identified as truly unhedgeable (no system has solved them)
- Status-seeking, herd mentality, and information hoarding identified as most designable
- 10 design principles derived from evidence, ordered by importance
- Agent Commons concept evaluated against principles: strong on Dunbar scale and renewal, critical gaps in separation of powers, plural AI governance, and extraction bounds
- 5 major risks identified for Agent Commons, with AI governance capture as the most critical
- 8 specific modifications recommended

### 2026-02-12: Corporatism Deep Research Completed
- Created `01-organizational-failures/CORPORATISM.md` (~850 lines)
- Full hedge-and-crack analysis of corporate hierarchy through human nature lens
- 6 hedges analyzed: Coase/transaction costs, limited liability, boards, competition, employment contracts, fiduciary duty
- 5 cracks with data and case studies: C-suite extraction (CEO pay 21:1 to 399:1), regulatory capture ($4.25B lobbying), Peter Principle (empirical validation), Innovator's Dilemma (Kodak/Blockbuster/Nokia/Sears), siloing (Microsoft stack ranking, Wells Fargo)
- Documented compounding death spiral with GE as archetype
- Analyzed 6 alternative structures (B-Corp, steward ownership, partnerships, founder-led, open-book, remote)
- Coase Question in AI Age: transaction cost reduction implies firm size shrinkage
- 60+ academic sources cited
- Honest assessment of what corporations do well included

### 2026-02-12: Effort Created
- Initialized effort with comprehensive research areas
- Structured research as trackable checklist
- Linked to goal G12.1

## Notes

The Agent Commons three-layer model (Agent → Forg → Commons) is one possible answer. Through this research, we may discover very different models that better serve the core question: **How can we steer AI-driven change toward a better world?**

Stay intellectually honest. Stay open to pivots. The goal is not to prove the Agent Commons concept—it's to find the best path forward.

## Tags

research, organizational-models, ai-society, exploration, post-corporate
