---
created: 2026-02-12T20:00:00Z
updated: 2026-02-13T00:00:00Z
type: research-area
parent_effort: EFFORT-Brainstorming-Research
area_number: 2
status: completed
---

# Research Area 2: AI-Driven Societal Changes

## Core Question

How does AI fundamentally reshape what's possible in human organization -- and what new structures emerge when knowledge, expertise, and capability are no longer scarce?

## Motivation

The entire Agent Commons premise rests on a belief that AI changes the game so fundamentally that new organizational models become both possible and necessary. This research area pressure-tests that belief. We need to understand *specifically* what AI changes, what stays the same, and what new problems it creates. Without this, we're building on assumptions.

## Research Threads

### 2.1 The Breakdown of Corporate Structure -- COMPLETED

**Question:** Does AI actually erode the economic logic that makes large corporations necessary?

**Output:** [[CORPORATE-BREAKDOWN]]

**Key findings:**
- Coase's transaction cost framework validated and extended with Williamson and Hart. AI reduces all categories of transaction costs, but by varying degrees (70-90% for search costs; 30-50% for asset specificity and incomplete contracts)
- The "1000x engineer" is hype; the honest number is 3-5x for average tasks. But this still reduces minimum viable teams from ~15 to ~3-5 people, which is structurally significant
- AI-native startups (Midjourney: $200M revenue, ~40 employees) demonstrate 5-25x revenue-per-employee compared to traditional companies
- Corporate layoffs explicitly citing AI: IBM, Klarna (700 agent-equivalents replaced), BT Group (55,000 planned), SAP, Chegg, Duolingo, Dropbox
- Corporate functions unbundling in sequence: customer service and content first, then legal/accounting, then consulting/analysis
- Physical manufacturing, regulated industries, capital-intensive industries, and network-effect platforms resist disaggregation
- The equilibrium is a "barbell distribution": very large platforms + very small AI-augmented teams, with the middle hollowed out
- Corporate inertia (legacy systems, middle management resistance, compliance overhead) is the Innovator's Dilemma repeating faster

### 2.2 Self-Organizing Teams -- COMPLETED

**Question:** How do small, AI-augmented teams actually form, coordinate, and deliver -- and what infrastructure do they need?

**Output:** [[SELF-ORGANIZING-TEAMS]]

**Key findings:**
- AI-native startups organize flat, remote-first, with 80-95% technical headcount and AI handling traditional corporate functions
- The management function decomposes into information processing (AI can handle), human relationships (AI cannot), and judgment (AI cannot). AI replaces ~60-70% of routine management
- Five closest Forg analogies studied: film production crews, consulting project teams, open-source sprints, music industry sessions, emergency response (ICS). ALL have hierarchy -- temporary and project-specific, but real
- Trust in temporary organizations operates through "swift trust" (categorical, role-based) not personal trust. Reputation systems must provide categorical trust signals
- All existing reputation systems have serious flaws (inflation, gaming, narrow scope). Building reputation that matches institutional trust is unsolved
- Optimal team sizes: 5-7 for tight coordination, 10-12 for self-management (Buurtzorg), ~150 as Dunbar boundary
- Self-organizing teams CAN handle large projects through nesting (Linux kernel model) but require: decomposition, hierarchical coordination of sub-teams, shared protocols, institutional infrastructure
- Seven infrastructure layers identified for the Agent Commons platform: Discovery, Coordination, Reputation, Payment, Trust, Legal, Quality -- plus the critical Governance layer
- Governance is the hardest and most important layer (the recursive governance problem from Area 1 applies)

### 2.3 Knowledge Democratization -- COMPLETED

**Question:** What happens when anyone can access expert-level capability through AI, and knowledge hoarding is no longer a competitive advantage?

**Output:** [[KNOWLEDGE-DEMOCRATIZATION]]

**Key findings:**
- AI is genuinely disrupting knowledge-based professions. Profession-by-profession analysis (legal, medical, financial, software engineering, education, creative, consulting) confirms real disruption, not hype
- Legal: AI handles 80-90% of contract review, but courtroom advocacy, client counseling, and strategic judgment remain human. Business model shift from billable hours underway
- Medical: AI matches specialists in bounded diagnostic tasks (imaging, structured diagnosis) but deployment lags capability due to regulation and liability. Greatest impact potential is global health access
- Software engineering: 46% of code on GitHub is AI-generated (2024). Most rapid measurable disruption. Junior developer roles most affected
- Five candidates for new power base when knowledge is free: capital (AI infrastructure), execution speed, taste/judgment, social capital, attention. No single winner -- likely a mix
- AI is a "leveling up" technology: Brynjolfsson study shows 34% improvement for novice workers vs. 0-5% for experts. But Matthew Effect in adoption means those with existing advantages adopt first
- The "taste layer" argument (humans curate, AI generates) is strong but may be temporary if AI develops judgment. Key uncertainty
- Digital Divide 2.0 has three layers: infrastructure access, AI literacy, AI agency. Each layer filters more people out
- Education implications: the credential vs. competence debate (Caplan) becomes more relevant as AI provides human capital directly. New models (micro-credentials, portfolios) emerging but unproven at scale
- Remaining scarcities: attention, trust, judgment, motivation, physical presence, authentic connection, original vision. Agent Commons should build value systems around these

### 2.4 Economic Implications -- COMPLETED

**Question:** How do the productivity gains from AI get distributed, and what new economic models might be needed?

**Output:** [[ECONOMIC-IMPLICATIONS]]

**Key findings:**
- Labor share of GDP has declined from ~65% (1970) to ~56-58% (2020). This is the baseline trend AI inherits
- Acemoglu vs. Autor debate: Acemoglu estimates AI adds only 0.53-0.66% TFP over 10 years (pessimistic); Autor argues new work categories will emerge but requires deliberate institutional choices. Both are right about different things
- Current data (2023-2025): No macro job destruction yet, but sector-specific displacement real (customer service, content creation, translation). Corporate profits at record levels -- gains flowing to capital, not labor
- UBI experiments: Finland (minimal employment effect, significant wellbeing improvement), Stockton (employment INCREASED, no vice spending), GiveDirectly (positive in developing contexts). None are conclusive for permanent, universal implementation
- Agent Commons economic model needs: hybrid value attribution (multiple signals, no single metric), progressive distribution (floor and ceiling mechanisms), 5-8% take rate, competition resilience through trust and alignment rather than subsidized pricing
- Winner-take-all dynamics: AI training concentrates (expensive), but AI usage democratizes (cheap). Open-source AI is the strongest concentration countermeasure. Barbell economy emerging
- Commons sustainability: historical open-source models (consulting, dual licensing, SaaS, sponsorship) provide precedent. Tiered pricing + marketplace fees + premium services most viable
- The commons model's competitive advantage vs. VC-funded platforms: trust, alignment, durability. Wins the marathon, must survive the sprint

## Desired Outputs

For each thread:
1. **Current state assessment** -- What's actually happening now, not just theory
2. **Trajectory analysis** -- Where is this heading in 2-5 years? 5-10 years?
3. **Implications for organizational design** -- What does this mean for Agent Commons or any alternative model?
4. **Open questions** -- What don't we know yet? What's genuinely uncertain?

## Success Criteria

- [x] Claims about AI's transformative impact are backed by evidence, not just hype (Threads 2.1, 2.2)
- [x] Both optimistic and pessimistic scenarios are explored honestly (Both threads include "honest assessment" sections)
- [x] Specific mechanisms identified (not just "AI changes everything" hand-waving) (Detailed transaction cost analysis, management function decomposition)
- [x] Clear connection drawn between AI capabilities and organizational model requirements (Platform specification in 2.2)
- [x] Economic sustainability of new models is addressed, not just the idealistic vision (Thread 2.4: commons economics, take rates, value attribution, sustainability models)
