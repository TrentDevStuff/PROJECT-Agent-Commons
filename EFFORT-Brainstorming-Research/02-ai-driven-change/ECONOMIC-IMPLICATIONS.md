---
created: 2026-02-12T23:30:00Z
updated: 2026-02-12T23:30:00Z
type: research
parent_effort: EFFORT-Brainstorming-Research
research_area: 02-ai-driven-change
thread: "2.4"
status: draft
backlinks:
  - [[RESEARCH]]
  - [[SYNTHESIS]]
  - [[KNOWLEDGE-DEMOCRATIZATION]]
  - [[HUMAN-NATURE-TAXONOMY]]
---

# 2.4 Economic Implications: Productivity, Distribution, and New Models

## Core Question

How do productivity gains from AI get distributed, and what new economic models might be needed?

## Why This Matters for Agent Commons

The Agent Commons concept proposes a new economic model: contribution-based rewards, AI governance, marketplace dynamics, and a commons that "takes a slice for sustainability." But this model exists within a broader economic context that AI is reshaping. Understanding how AI productivity gains are distributed -- and why historical patterns suggest they will concentrate -- is essential for designing an economic model that actually spreads prosperity. The Area 1 synthesis identified rent-seeking and extraction as persistent failure modes; this thread examines whether AI changes or amplifies those dynamics.

---

## 1. Productivity Distribution: The Historical Pattern and Whether AI Breaks It

### 1.1 The Declining Labor Share

**The data is unambiguous: labor's share of national income has been declining in developed economies since the 1970s.**

The U.S. labor share of GDP declined from approximately 65% in 1970 to approximately 56-58% by 2020 (Bureau of Labor Statistics data; Karabarbounis and Neiman, 2014, "The Global Decline of the Labor Share," *Quarterly Journal of Economics*). This means that for every dollar of GDP produced, workers receive less and capital owners receive more than they did 50 years ago.

The trend is global. Karabarbounis and Neiman documented labor share declines in 42 of 59 countries studied between 1975 and 2012. The ILO's Global Wage Report confirmed the trend through 2024: real wage growth has lagged productivity growth in most economies for decades.

**Causes (pre-AI):**
- Automation of routine tasks (manufacturing robots, ATMs, self-checkout)
- Globalization (offshoring to lower-wage countries)
- Declining unionization (U.S. union membership: 35% in 1955, 10% in 2024)
- Rising market concentration (fewer firms, more market power)
- Shift from labor-intensive to capital-intensive industries
- "Superstar firm" effects (Autor et al., 2020): the most productive firms capture larger market shares, and these firms have lower labor shares

### 1.2 Is AI Different? The Acemoglu vs. Autor Debate

This is the central academic debate about AI's economic impact. The two most influential economists on the topic arrive at sharply different conclusions.

**Daron Acemoglu (MIT) -- The Pessimist:**

Acemoglu's position, articulated most fully in "The Simple Macroeconomics of AI" (2024, NBER Working Paper) and with Pascual Restrepo in multiple papers (2018, 2019, 2020, 2022):

*Core argument:* AI will displace workers from tasks without creating sufficient new tasks or productivity gains to compensate. The historical pattern -- technology displaces, then creates new work -- may not hold because:

1. **AI automates tasks but does not create new tasks as rapidly as previous technologies.** The steam engine created factory work. Computers created programming. AI automates existing cognitive tasks but the new tasks it creates (prompt engineering, AI training) are smaller in number and employ fewer people.

2. **Productivity gains from AI are overstated.** Acemoglu estimates AI will increase total factor productivity by only 0.53-0.66% over 10 years -- meaningful but far below the 15-30% gains touted by Goldman Sachs and McKinsey. His reasoning: only a fraction of tasks are automatable, only a fraction of those will actually be automated (institutional inertia, regulation, cost), and the tasks automated are not the most productive ones.

3. **The "so-so automation" problem.** Acemoglu and Restrepo (2019) introduced this concept: many AI applications automate tasks without dramatically improving productivity -- they just replace workers with machines that are only marginally better (or sometimes worse). Self-checkout machines are "so-so automation" -- they displace cashiers without significantly improving the checkout experience. This displaces labor without creating sufficient productivity gains to generate new employment.

4. **AI is capital-biased.** AI requires massive capital investment (compute, data, infrastructure). Returns accrue to capital owners. The declining labor share will accelerate under AI unless countervailing policies intervene.

*Specific predictions:* AI will increase inequality, concentrate wealth among AI infrastructure owners, displace significant numbers of workers from middle-skill cognitive tasks, and produce only modest aggregate productivity gains. The right policy response is not UBI (which Acemoglu opposes as giving up on employment) but taxation of AI, investment in human capital, and policies that steer AI development toward augmenting workers rather than replacing them.

**David Autor (MIT) -- The Cautious Optimist:**

Autor's position, articulated in "The Labor Market Impacts of Technological Change" (2022), "New Frontiers: The Origins and Content of New Work, 1940-2018" (2024, *Quarterly Journal of Economics*), and various presentations:

*Core argument:* AI will create entirely new categories of work, just as every previous technology wave has done. But this requires deliberate institutional choices to steer AI toward augmentation rather than replacement.

1. **The "new work" hypothesis.** Autor and colleagues (2024) documented that approximately 60% of jobs in 2018 did not exist in 1940. The vast majority of employment growth over the past 80 years has been in jobs that were created by technological change, not in existing jobs that technology made more productive. The question is whether AI will continue this pattern.

2. **The "tasks, not jobs" framework.** AI automates specific tasks within jobs, not entire jobs. Even professions heavily affected by AI (law, medicine, software engineering) still contain tasks that AI cannot perform. The result is not job elimination but job transformation -- the same profession with a different task composition.

3. **AI as the great equalizer (potentially).** Autor has argued (2024 Hamilton Project paper) that AI could reverse the polarization of the labor market by providing expert-level capabilities to middle-skill workers. If a medical assistant with AI tools can handle diagnostic tasks that currently require a physician, the value of medical assistant work increases. This is knowledge democratization creating economic democratization -- *if* the gains are captured by workers rather than only by employers.

4. **Institutional choice matters.** Autor does not predict a positive outcome -- he argues that the outcome depends on policy. AI *could* augment workers and broaden prosperity, or it *could* displace workers and concentrate wealth. The technology is neutral; the institutional choices determine the outcome.

**Assessment of the debate:**
Both are right about different things. Acemoglu is right that AI is capital-intensive, that "so-so automation" is a real pattern, and that the historical tendency is for productivity gains to accrue to capital. Autor is right that new categories of work typically emerge, that tasks transform rather than entire jobs disappearing, and that institutional choices matter enormously.

The critical uncertainty: *pace*. If AI creates new work at roughly the same pace it destroys old work, the transition is manageable (Autor's scenario). If AI destroys work faster than it creates new work -- even temporarily -- the transition produces massive economic disruption (Acemoglu's concern). Historical precedent (the Industrial Revolution produced 50-100 years of declining living standards for workers before gains materialized) suggests that even ultimately positive transitions can involve generations of suffering.

### 1.3 What Does Current Data Say? (2023-2025)

**Job market data:**
- U.S. unemployment remained at or below 4% through 2024, suggesting no macro-level job destruction yet. But aggregate unemployment masks compositional shifts -- specific sectors and skill levels are affected while others are not.
- The BLS Occupational Outlook Handbook shows growing employment in AI-adjacent fields (data science, machine learning engineering) and in human-centered services (healthcare, education, social work), while clerical and administrative roles continue declining.
- Freelance and gig work platforms reported shifts. Upwork's 2024 data showed that demand for routine writing, basic design, and simple programming declined 20-40%, while demand for AI-augmented creative direction, AI integration, and strategic consulting increased.
- Layoffs in tech (2023-2024) were partly attributed to AI efficiency gains. Google, Meta, Amazon, Microsoft, and other major tech companies cut tens of thousands of positions, with leadership explicitly citing AI-driven productivity improvements.
- However, tech layoffs were also driven by post-pandemic overexuberant hiring. Disentangling AI displacement from cyclical correction is difficult.

**Wage data:**
- Real wages for most U.S. workers grew modestly from 2022-2024, driven partly by a tight labor market and minimum wage increases in several states.
- The wage premium for AI skills increased sharply. LinkedIn data showed that jobs requiring "generative AI" skills offered 30-40% wage premiums over similar jobs without that requirement.
- The wage premium for routine cognitive skills (data entry, bookkeeping, basic analysis) continued its long-term decline.

**Corporate profits and concentration:**
- The "Magnificent Seven" (Apple, Microsoft, Nvidia, Amazon, Alphabet, Meta, Tesla) accounted for over 60% of S&P 500 returns in 2023 and a substantial share in 2024. AI is driving unprecedented stock market concentration.
- Corporate profit margins reached near-record levels (S&P 500 net profit margin ~11-12% in 2024), suggesting that productivity gains from AI are flowing to profits, not wages, so far. This is consistent with Acemoglu's prediction and the historical pattern.

---

## 2. Employment Disruption

### 2.1 Which Jobs Have Already Been Affected?

Documenting actual AI displacement is difficult because companies rarely attribute layoffs explicitly to AI (legal and reputational risk). But convergent evidence points to specific categories:

**Customer service / call centers:**
Klarna (Swedish fintech) reported in 2024 that its AI chatbot was handling two-thirds of customer service inquiries, performing the work equivalent of 700 full-time agents. Customer satisfaction scores were equal to or higher than human agents. Klarna subsequently reduced headcount from approximately 5,000 to approximately 3,800.

Multiple major customer service operations (banks, telecom, retail) deployed AI chatbots in 2023-2024. While few published specific displacement numbers, industry analysts estimated that 20-30% of customer service agent roles in large enterprises were affected.

**Content creation and copywriting:**
Freelance content writing was among the first visibly disrupted markets. Rates on platforms like Upwork and Fiverr for blog posts, product descriptions, and social media content dropped significantly (30-50% in affected categories). Some estimates suggest the number of active freelance writers on major platforms declined 20-30% from 2022 to 2024.

News organizations including CNET, Sports Illustrated, and BuzzFeed experimented with AI-generated articles, some controversially without disclosure. The Associated Press has used AI to generate routine earnings reports since 2014. By 2024, AI-generated first drafts were standard practice in many newsrooms.

**Translation and interpretation:**
AI translation quality improved dramatically with GPT-4 and Gemini. Professional translation demand for routine documents (business correspondence, technical manuals, web content) declined. The translation industry was estimated to have lost 10-15% of volume to AI by 2024. However, demand for high-quality literary translation and localization remained strong -- an instance of the "execution commoditized, judgment elevated" pattern.

**Graphic design and illustration:**
As discussed in the Knowledge Democratization thread, AI image generation (Midjourney, DALL-E, Stable Diffusion) displaced significant demand for stock illustration, concept art, and routine design work. The Concept Art Association reported 70% of members experiencing reduced work opportunities.

**Data entry and processing:**
Already in long-term decline due to earlier automation, AI accelerated the trend. OCR combined with AI can now process and categorize documents with near-human accuracy. Insurance claims processing, invoice handling, and medical records management are increasingly AI-automated.

### 2.2 The "Tasks, Not Jobs" Framework and Its Limits

Autor's insight -- that AI automates tasks within jobs rather than entire jobs -- is empirically supported. Most professions contain a mix of AI-automatable and AI-resistant tasks. A lawyer's job includes contract review (automatable), legal research (automatable), client counseling (not automatable), courtroom advocacy (not automatable), and relationship management (not automatable). AI handles the first two, transforming the job rather than eliminating it.

**But there is a threshold problem.** When AI automates 20-30% of a job's tasks, the remaining tasks may not constitute a full-time role. If AI handles routine legal research and contract review, a law firm needs fewer junior associates -- not zero associates, but fewer. The tasks that remain (client counseling, advocacy) require skills that junior associates are still developing. The result is not job elimination but career pipeline compression -- fewer entry-level positions, higher entry barriers, and a squeeze on the middle of the profession.

This pattern -- "fewer workers doing higher-level work" -- has been called the "hourglass economy": many jobs at the top (creative, strategic, interpersonal), many jobs at the bottom (physical, care-based, low-cost-threshold), and a hollowed-out middle (routine cognitive work that AI handles).

### 2.3 Post-Work Economics

The question is not just near-term disruption but the long-term trajectory: what happens if AI eventually handles *most* cognitive labor?

**Keynes revisited:**
John Maynard Keynes's 1930 essay "Economic Possibilities for Our Grandchildren" predicted that by 2030, productivity growth would allow humans to work 15-hour weeks and devote the rest to leisure, relationships, and culture. The productivity growth happened; the leisure society did not. Why?

Skidelsky and Skidelsky (*How Much Is Enough?*, 2012) argue that Keynes underestimated the insatiability of wants (hedonic adaptation, relative status competition) and the power of institutions designed to maintain full employment. Even when technology makes less work necessary, social structures push people to work the same or more hours -- partly because work provides identity, social connection, and purpose, not just income.

**The meaning-of-work question:**
If AI handles production, what provides people with:
- **Purpose and identity:** Research consistently shows that unemployment is psychologically devastating beyond income loss. Jahoda (1982, *Employment and Unemployment*) identified five latent functions of work: time structure, social contact, collective purpose, social identity/status, and regular activity. Winkelmann (2014) found that the life satisfaction loss from unemployment exceeds what can be explained by income loss alone.
- **Social connection:** Workplaces are the primary source of adult social connection for many people. Remote work during COVID demonstrated both the possibility and the social costs of disconnection.
- **Dignity and self-worth:** The Protestant work ethic remains culturally powerful. "What do you do?" is the first question at any social gathering. Graeber's *Bullshit Jobs* (2018) documented that even people with meaningless jobs preferred having a job to not having one.

**Possible responses:**
- **Redefine work** to include care, community service, creative expression, environmental stewardship -- activities that are valuable but currently unpaid or underpaid.
- **Separate income from employment** through UBI or similar mechanisms (Section 3 below).
- **Create new categories of meaningful work** that AI cannot do -- exactly what the Agent Commons concept attempts.
- **Accept a leisure society** and address the meaning question through culture, community, and personal development rather than employment.

### 2.4 New Categories of Work AI Is Creating

Counterbalancing displacement, AI is creating new work categories:

**Explicitly AI-related:**
- Prompt engineers / AI interaction designers ($100,000-300,000 in 2024 job postings)
- AI trainers / data annotators (large-scale: Scale AI employed 100,000+ annotators globally)
- AI safety researchers and alignment engineers
- AI ethicists and governance specialists
- AI-human interaction designers

**AI-enabled new categories:**
- AI-augmented creators (using AI tools to produce work impossible without them)
- AI integration specialists (deploying AI in existing business processes)
- "Human-in-the-loop" specialists (supervising AI systems, handling edge cases)
- AI-literacy educators and corporate AI trainers
- Personalized experience designers (using AI to create hyper-customized products/services)

**Are these enough?**
The scale of new AI-related employment is modest compared to the potential displacement. Scale AI's 100,000+ data annotators are significant, but the work is often low-paid, repetitive, and itself subject to automation. Prompt engineering may be a temporary role that disappears as AI becomes better at understanding natural language. The high-paid AI-related jobs (ML engineers, AI researchers) require skills that are rare and concentrated.

Autor's "new work" research suggests that the truly large-scale new job categories will be ones we cannot currently predict -- just as no one in 1940 could have predicted that "web developer" or "social media manager" would employ millions. The question is timing: how long between displacement and creation?

---

## 3. UBI and Alternatives: Distributing AI Productivity Gains

### 3.1 Universal Basic Income (UBI)

**The concept:** Every citizen receives a regular, unconditional cash payment sufficient to cover basic needs. No means testing, no work requirements, no conditions.

**Major experiments and findings:**

**Finland (2017-2018):**
- Design: 2,000 unemployed individuals received EUR 560/month unconditionally for two years (control group: 173,000 unemployed who received standard benefits with conditions).
- Employment effect: Minimal. Treatment group worked approximately 6 more days per year than control group. Not statistically significant in the first year, modestly significant in the second.
- Wellbeing effect: Significant. Treatment group reported higher life satisfaction, better perceived health, greater trust in institutions, and reduced stress compared to control.
- Limitations: Sample was only unemployed individuals (not universal), payment was modest (below poverty line), and duration was short (2 years, known to be temporary).
- Key finding: UBI did not reduce employment motivation (contradicting the "moral hazard" criticism) but also did not significantly increase employment. The primary effect was psychological wellbeing.

**Stockton SEED (2019-2021):**
- Design: 125 residents of Stockton, California (population ~310,000, median income well below national average) received $500/month unconditionally for two years.
- Employment effect: Positive. Full-time employment among recipients increased from 28% to 40% during the study period, compared to 32% to 37% in the control group. The cash provided stability that enabled job searching, childcare, and transportation.
- Spending patterns: Recipients spent primarily on food (37%), sales/merchandise (22%), utilities (11%), and auto costs (10%). Less than 1% was spent on alcohol or tobacco -- contradicting the "they'll waste it on vices" criticism.
- Wellbeing: Reduced financial anxiety, increased ability to handle unexpected expenses. Treatment group reported significantly less income volatility.
- Limitations: Small sample, short duration, modest amount, funded by private philanthropy.

**GiveDirectly (ongoing, multiple countries):**
- Design: Unconditional cash transfers to extremely poor individuals in Kenya, Uganda, Rwanda, and other countries. Multiple program designs: lump-sum, monthly, and 12-year long-term.
- Findings (Kenya long-term study, preliminary results 2023-2024): Recipients invested in assets (housing, livestock, businesses), increased consumption, and reported improved wellbeing. Children's education outcomes improved. Importantly, no significant increase in alcohol or tobacco consumption, and neighboring non-recipients did not report negative spillover effects.
- Scale: GiveDirectly has transferred over $600 million to approximately 1.5 million individuals across 14 countries.
- Key insight: In extremely poor contexts, unconditional cash transfers are consistently among the most cost-effective development interventions. The question is whether this generalizes to developed-country contexts.

**Andrew Yang's proposal (2020 presidential campaign):**
- "Freedom Dividend": $1,000/month ($12,000/year) to every U.S. adult citizen
- Funded by a 10% Value Added Tax (VAT) on goods and services
- Cost estimate: approximately $2.8 trillion per year (roughly 12% of GDP)
- Economic analysis: The Roosevelt Institute modeled Yang's proposal and estimated it would grow the economy by $2.5 trillion over 8 years (assuming federal deficit financing) or be revenue-neutral with lower growth (assuming full tax funding). These estimates were contested.

**Criticisms of UBI:**

*Inflation risk:* If everyone receives an additional $1,000/month, won't prices simply rise? Standard economic theory suggests that if UBI is funded by redistribution (not money printing), the effect on overall price levels is modest -- it changes who spends the money, not the total money supply. However, in specific markets (housing, where supply is constrained), price increases are likely. Empirical evidence from cash transfer experiments shows minimal inflation effects, but these are small-scale; economy-wide effects could differ.

*Moral hazard / work disincentive:* The Finland and Stockton experiments found no significant reduction in work motivation, and Stockton found an increase in employment. However, these experiments were short-duration and participants knew they were temporary. A permanent, truly universal program might produce different effects. The "income effect" in economics predicts that higher non-labor income reduces labor supply; the question is magnitude.

*Fiscal feasibility:* A UBI sufficient for basic needs ($12,000-24,000/year per adult in the U.S.) would cost $2.8-5.6 trillion per year. The entire federal budget is approximately $6.5 trillion. This would require either massive tax increases, reallocation from existing programs, or deficit financing. This is the most serious practical objection -- not that UBI is unaffordable in principle, but that the political will for the required taxation does not exist.

*Loss of purpose:* The "meaning of work" problem (Section 2.3). If UBI replaces the need to work, and work provides meaning, identity, and social connection, what fills the gap? UBI proponents argue that it enables people to pursue meaningful unpaid work (care, art, community service). Critics argue that in practice, people without structured work obligations become isolated and depressed. The evidence is genuinely mixed.

### 3.2 Contribution-Based Distribution (Agent Commons Model)

**The concept:** Rewards flow to those who contribute, not to those who own capital or hold positions. Contribution is tracked, measured, and rewarded proportionally. This is the economic model implicit in the Agent Commons concept.

**How it would work economically:**
- Agents contribute to Forgs (project teams). Contribution is tracked through the commons infrastructure.
- Forgs produce outputs that are published and monetized through the commons (app-store model).
- Revenue is distributed: a slice to the commons for sustainability, the remainder to contributors proportional to their contribution.
- Value attribution is the critical mechanism: how is contribution measured?

**Closest existing models:**
- **Open-source bounties:** Gitcoin, bounty.network, and similar platforms post bounties for specific contributions. Contributors are paid for completed work. This works for well-defined tasks but struggles with ambiguous contribution (who gets credit for a great conversation that inspired the breakthrough?).
- **Creator economy:** YouTube (ad revenue sharing), Substack (subscription sharing), Spotify (stream-based royalties). These platforms distribute revenue to creators based on consumption metrics. The economics are famously winner-take-all: the top 1% of creators capture the vast majority of revenue.
- **Gig platforms:** Uber, Upwork, Fiverr. These platforms match workers with tasks and take a platform fee (typically 15-30%). They provide flexibility but have been criticized for transferring risk to workers, suppressing wages, and creating precarious employment.
- **Film industry:** Hollywood's project-based model -- crews assemble for a project, produce the work, dissolve, and reassemble for the next project -- is the closest analogy to the Forg concept. Compensation combines upfront payment (daily/weekly rates) with residuals (ongoing revenue share for some roles). The model works but produces extreme inequality between above-the-line (producers, directors, stars) and below-the-line (crew) compensation.

**Economic challenges:**

*Value attribution:* How do you measure contribution to a collective output? Git commits count code volume but not code quality. Time invested does not equal value created. Peer review introduces subjective bias. Market signals (revenue generated) are noisy and delayed. This is the hardest problem in contribution-based economics.

Possible approaches:
- **Commit-based** (git model): Track all contributions, weight by peer review or automated quality assessment. Problem: favors measurable contributions over ambiguous ones.
- **Revenue-based** (market model): Pay contributors based on the market value of outputs they contributed to. Problem: winner-take-all dynamics, delayed feedback.
- **Peer assessment** (cooperative model): Contributors assess each other. Problem: social dynamics, reciprocal favoritism, gaming.
- **Hybrid**: Combine multiple signals -- market revenue, peer assessment, contribution volume, AI-assessed quality. Most robust but most complex.

*Platform fee / take rate:* The commons "takes a slice for sustainability." What is the right rate?
- Apple App Store: 30% (widely criticized as extractive)
- Steam (gaming): 30% (standard for the industry)
- Stripe (payments): 2.9% + $0.30 per transaction
- Substack: 10% of subscription revenue
- Shopify: variable, but approximately 2-3% of transaction volume
- Open-source model: 0% (funded through other means -- consulting, sponsorship, dual licensing)

The take rate determines whether the commons is a platform (extractive, high take rate) or a utility (enabling, low take rate). The Agent Commons concept should aim for the lowest sustainable take rate to maximize value flow to contributors. But sustainability requires covering infrastructure costs, AI governance costs, dispute resolution, and development -- which are non-trivial.

*Sustainability without VC:* Can a commons compete with VC-funded platforms that can subsidize costs to acquire users? The VC-funded platform can operate at a loss for years, capturing market share through below-cost pricing, then raise prices once dominant (the "predatory pricing" strategy that built Uber, DoorDash, and others). A commons that must sustain itself from contributions cannot match this strategy.

Counter-argument: VC-funded platforms must eventually extract more value than they provide (to repay investors). A commons does not have this obligation. If the commons can reach sustainability without investor pressure, it may offer better long-term economics to participants. The challenge is surviving the initial period before reaching sustainability.

### 3.3 Stakeholder Capitalism

**The concept:** Corporations should serve all stakeholders (employees, customers, communities, environment) rather than just shareholders. Profit maximization is replaced by value creation for all stakeholders.

**Business Roundtable 2019 statement:**
In August 2019, 181 CEOs of the Business Roundtable (America's most prominent corporate lobbying group) signed a statement redefining the "purpose of a corporation" to serve all stakeholders. Signatories included the CEOs of Amazon, Apple, JP Morgan, and dozens of other major corporations.

**Implementation vs. rhetoric:**
Academic analysis (Bebchuk and Tallarita, 2020, "The Illusory Promise of Stakeholder Governance," *Cornell Law Review*) found no evidence that signatory companies changed their behavior after signing. CEO compensation continued rising. Share buybacks continued at record levels. Environmental commitments showed no meaningful acceleration. The statement appears to have been a public relations exercise -- stakeholder capitalism as performance, not practice.

This is a direct illustration of the self-deception dynamic identified in the Area 1 synthesis: CEOs genuinely believed (or at least genuinely said) they were serving all stakeholders while their actual behavior remained shareholder-focused.

**Models that do have teeth:**
- **B-Corp certification:** Over 7,000 certified B-Corps globally by 2024 (Patagonia, Allbirds, Ben & Jerry's, etc.). B-Corps must meet verified social and environmental performance standards. However, B-Corp certification is voluntary and can be abandoned -- Etsy decertified in 2017 after going public.
- **Benefit corporations:** Legal structure available in 40+ U.S. states. Directors are legally authorized to consider stakeholder interests, not just shareholder profit. This provides legal cover but not legal obligation -- directors *may* consider stakeholders but are not required to.
- **European codetermination:** Germany's Mitbestimmung (codetermination) law requires companies with 500+ employees to reserve one-third of supervisory board seats for worker representatives (one-half for companies with 2,000+). This is the strongest existing mechanism for worker voice in corporate governance. Research (Gorton and Schmid, 2004; Jager et al., 2021) suggests codetermination reduces wage inequality and has neutral or slightly positive effects on productivity.

**Assessment:** Stakeholder capitalism as voluntary commitment does not work (the Business Roundtable evidence). Stakeholder capitalism as legal structure (benefit corporations, codetermination) shows more promise but has limited adoption. The lesson for Agent Commons: structural requirements (constitutional constraints, as the Area 1 synthesis recommended) are necessary; voluntary commitments to stakeholder welfare are insufficient.

### 3.4 Public AI Dividends

**The concept:** If AI generates massive economic value, some portion should be distributed to the public -- either because AI was trained on public data, because AI reduces the need for labor, or simply because the gains should be shared.

**Alaska Permanent Fund as model:**
- Established 1976. Alaska constitutionally dedicates a portion of oil revenue to a state-owned investment fund.
- The fund distributes an annual dividend to every Alaska resident. The dividend has ranged from approximately $800 to $3,200 per person since 1982.
- Funded by a natural resource (oil) that is constitutionally recognized as belonging to the public. The analogy: if data is the "new oil" and AI is built on public data, the public has a claim on AI's economic output.
- The fund has been politically durable for 40+ years because every resident benefits directly. This creates a broad constituency that resists attempts to divert the fund.
- Net effect: Alaska has the lowest income inequality of any U.S. state (Gini coefficient), attributable partly to the dividend. The dividend has had measurable positive effects on child health, education, and poverty reduction.

**Proposals for AI-specific dividends:**

*Bill Gates' "robot tax" (2017):* Gates proposed taxing companies that use automation to replace human workers. The tax revenue would fund social programs and transition support. Criticism: defining what constitutes "automation replacing a worker" is difficult, and the tax could slow beneficial adoption of productivity-enhancing technology.

*Data dividends:* If AI companies train on public data (internet content, social media posts, government data), the individuals who created that data have a claim on the resulting value. California's proposed "Data Dividend" (2019, not enacted) would have required tech companies to share a portion of data revenue with the state's residents. Andrew Yang incorporated a similar idea into his campaign platform. The challenge: attributing the value of individual data contributions to a collective AI output is essentially impossible -- my single Reddit post contributes immeasurably to GPT-4's capability.

*Public AI compute infrastructure:* Instead of cash dividends, provide public access to AI compute. The National AI Research Cloud (NAIRRC) concept, endorsed by a bipartisan commission in the U.S. (2023), would create government-funded AI compute infrastructure accessible to researchers, startups, and the public. This is a public goods approach: rather than distributing cash from AI profits, distribute AI capability directly.

*Sovereign AI funds:* Several countries (UAE, Saudi Arabia, Singapore, France) have established national AI investment funds. These are not dividend-distributing funds (like Alaska's) but government investment vehicles. A hybrid approach -- a sovereign AI fund that generates returns and distributes dividends -- has been proposed by various economists but not implemented.

### 3.5 Other Distribution Models

**Profit sharing / employee ownership:**
- U.S. ESOPs (Employee Stock Ownership Plans): Over 6,500 companies with approximately 14 million participants. ESOP companies have demonstrated higher productivity, lower employee turnover, and greater resilience during recessions (NCEO data).
- The "Mondragon model" (see Area 1): Worker ownership with democratic governance. Demonstrated viability for 65+ years.
- AI-era challenge: If companies need fewer workers (Acemoglu's scenario), employee ownership concentrates gains among a shrinking workforce. Broad-based ownership requires mechanisms beyond employment-linked ownership.

**Universal basic services (UBS):**
Rather than cash (UBI), provide universal access to housing, healthcare, education, transportation, and digital connectivity. The Institute for Global Prosperity (IGP, University College London) modeled UBS for the UK and estimated it could be delivered for approximately 2.3% of GDP.

Advantages over UBI: Directly addresses needs, less subject to inflation risk, reduces cost of living. Disadvantages: Paternalistic (decides what people need), less flexible than cash, creates large public bureaucracies.

**Negative income tax (NIT):**
Milton Friedman's proposal (1962): instead of a universal payment, provide a guaranteed minimum income through the tax system. If you earn below the threshold, you receive payments; if above, you pay taxes. The NIT is mathematically equivalent to a UBI-plus-tax combination but has different political framing (it looks like "helping the poor" rather than "giving everyone money").

The U.S. Earned Income Tax Credit (EITC) is a partial NIT. Research consistently shows the EITC increases employment and reduces poverty. But it is conditioned on earned income -- it helps low-wage workers, not the unemployed.

---

## 4. New Forms of Value

### 4.1 If AI Handles Production, What Becomes Valuable?

The economic question is: if AI can produce competent text, images, music, code, analysis, strategy, and design, what is left for humans to sell?

**Curation and taste:**
In a world of infinite AI-generated content, the ability to select, contextualize, and present the right content to the right audience becomes valuable. This is already the business model of social media influencers, newsletter curators, playlist creators, and gallery owners. AI amplifies this by increasing the supply of content (making curation more necessary) while also potentially automating curation itself (making human curation less scarce).

**Human connection:**
Therapy, coaching, mentoring, care work, and community building are all growing sectors. The Bureau of Labor Statistics projects that healthcare support occupations will grow by 15-20% from 2022 to 2032 -- faster than any other sector. This is partly demographic (aging population) and partly reflects the premium on genuine human presence. AI chatbots can provide CBT techniques, but they cannot provide the relational warmth and genuine understanding that makes therapy effective.

**Meaning-making:**
Philosophy, spiritual guidance, leadership, narrative, art criticism, and cultural commentary. As material needs are met and routine cognitive work is automated, the human need for meaning becomes more salient. Victor Frankl's insight -- that meaning, not pleasure or power, is the fundamental human motivation -- may become increasingly relevant.

**Experience:**
Live events, travel, physical interaction, embodied presence. The "experience economy" (Pine and Gilmore, 1998, *The Experience Economy*) argued that economic value was shifting from goods to services to experiences. AI accelerates this by commoditizing goods and services further, making experiences the premium. Concert attendance, restaurant dining, travel, sports events, and social gatherings are all experience goods that AI cannot replicate.

**Trust and authenticity:**
"Made by humans" as a premium marker. The artisanal movement predates AI but finds new relevance: handmade pottery, live music performance, human-authored literature, hand-cooked meals. When AI can produce a technically perfect painting, the human-painted version becomes more valuable *because* it is human -- a reversal of the efficiency logic that has driven economic value for centuries.

Research on the "authenticity premium" (Newman and Bloom, 2012, *Cognition*) shows that people value objects more when they are perceived as authentic originals rather than identical copies. This psychological mechanism could support a "human premium" in an AI-saturated market.

### 4.2 The Experience Economy, AI-Amplified

Pine and Gilmore's framework:
```
Raw materials → Goods → Services → Experiences → Transformations
   (extract)    (make)   (deliver)   (stage)       (guide)
```

AI pushes economic value rightward along this progression:
- **Raw materials**: Unchanged by AI
- **Goods**: Production increasingly automated, commoditized
- **Services**: Knowledge-based services (legal, medical, financial advice) partially automated
- **Experiences**: Uniquely human, premium-priced, growing sector
- **Transformations**: Personal growth, education, coaching, therapy -- the highest-value layer, most resistant to AI

The implication for Agent Commons: the value system should recognize and reward contributions across this entire spectrum, but particularly in the higher-value, more human layers. An economic model built only on goods and services production will be increasingly automated. An economic model that also values experience design, relationship building, and transformational impact will be more durable.

---

## 5. Winner-Take-All Dynamics

### 5.1 Does AI Amplify Concentration or Enable Distribution?

**Evidence for concentration:**

*AI training costs*: Training frontier models costs $100M-$10B. Only a handful of companies can afford this. Nvidia, Microsoft, Google, Amazon, and Meta dominate AI infrastructure spending. This creates an oligopoly at the foundation layer.

*Network effects*: AI-powered platforms exhibit strong network effects. More users generate more data, which improves the AI, which attracts more users. This is the same dynamic that created Google's search monopoly and Facebook's social monopoly. AI may create even stronger lock-in because switching costs are higher (your data, your trained workflows, your customized models are tied to the platform).

*Talent concentration*: A 2024 analysis estimated that fewer than 100,000 people worldwide have the skills to develop frontier AI systems. They are concentrated in a handful of companies in a handful of cities. This talent scarcity creates a bottleneck that concentrates power.

*Revenue concentration*: The "superstar firm" phenomenon (Autor et al., 2020) is intensifying. The top AI companies are capturing an increasing share of total technology revenue and market capitalization. The gap between AI leaders and laggards is widening.

**Evidence for distribution:**

*AI tools are cheap to use*: While training frontier models is expensive, using them is cheap and getting cheaper. An API call that cost $1 in 2020 costs $0.01 in 2025. This means that any small team can access the same AI capabilities as a large corporation for minimal cost.

*Small teams achieve enterprise-level output*: Midjourney (11 people, $200M+ revenue). WhatsApp at acquisition (55 employees, 450M users). Instagram at acquisition (13 employees, 30M users). AI amplifies this pattern further -- a team of 5 with AI tools can potentially match the output of a team of 50 without them.

*Open-source AI*: Meta's Llama models, Mistral, Stability AI's open weights, and many others provide competitive AI capability at no licensing cost. The open-source AI ecosystem is vibrant and growing. If the frontier models are within reach of open-source alternatives, the concentration thesis weakens.

*Reduced barriers to entry*: AI reduces the cost and time required to build products, enter markets, and serve customers. This should theoretically increase competition, not decrease it.

### 5.2 Network Effects in AI

The critical question is whether AI-powered platforms create stronger or weaker lock-in than pre-AI platforms.

**Arguments for stronger lock-in:**
- AI systems learn from user data. The more you use a platform, the better it understands you. Switching platforms means starting the learning from scratch.
- Custom AI models trained on company data represent significant switching costs.
- Integration depth: AI systems are integrating into core business processes, making them harder to replace than standalone software.

**Arguments for weaker lock-in:**
- Commoditization of AI capability: If multiple providers offer similar capabilities (GPT-4 vs. Claude vs. Gemini vs. Llama), switching is easier.
- Open standards: Emerging open standards for AI model formats, APIs, and data formats reduce lock-in.
- Interoperability requirements: Regulatory pressure (EU AI Act, Digital Markets Act) may mandate data portability and interoperability.

### 5.3 Open-Source AI as Concentration Countermeasure

Open-source AI (Meta's Llama, Mistral, Stability AI, Hugging Face ecosystem) is the most powerful countermeasure against AI concentration. It provides:
- Free access to competitive AI models
- Ability to customize and fine-tune models for specific needs
- Independence from any single company's pricing, policies, or availability
- Community-driven innovation and improvement
- Transparency (model weights are inspectable, unlike proprietary black boxes)

**Limitations of open-source AI:**
- Frontier performance still requires proprietary models (as of early 2025, GPT-4o and Claude 3.5 Opus outperform open-source alternatives on most benchmarks)
- Training open-source models still requires massive compute (Meta invested billions in training Llama)
- Maintenance, updates, and support are not guaranteed for open-source models
- Liability and accountability are unclear for open-source AI applications

**Assessment:** Open-source AI significantly mitigates AI concentration risk but does not eliminate it. The infrastructure layer (compute, data centers, chips) remains concentrated regardless of whether models are open-source. Open-source AI is necessary but not sufficient for preventing winner-take-all dynamics.

---

## 6. The Commons Model Economics

### 6.1 How Would an Agent Commons Actually Sustain Itself?

This is the most practically important question for the Agent Commons concept. An economic model must be not just fair but sustainable -- it must generate enough revenue to cover costs and attract enough participants to reach critical mass.

**Revenue model options:**

*Transaction fees (marketplace model)*:
The commons takes a percentage of every transaction between agents, forgs, and end users. This is the Stripe/Shopify model -- the platform takes a small cut of every transaction it facilitates.
- Advantage: Aligns platform revenue with participant success (the commons earns more when participants earn more)
- Disadvantage: Requires sufficient transaction volume to be sustainable; incentivizes the commons to maximize transactions rather than maximize participant welfare
- Suggested range: 5-15% (lower than app store models, higher than payment processors)

*Subscription fees (SaaS model)*:
Agents pay a monthly/annual fee for commons access, tools, and governance services.
- Advantage: Predictable revenue, decouples platform incentive from transaction volume
- Disadvantage: Creates barriers to entry (especially for new participants who have not yet earned), may exclude those who cannot pay
- Could be combined with a freemium model: basic access free, premium features (AI governance, advanced tools, priority dispute resolution) paid

*Tiered services*:
Free tier: basic commons access, standard AI governance
Pro tier: enhanced AI tools, priority dispute resolution, advanced contribution analytics
Enterprise tier: custom governance, dedicated AI resources, white-label commons infrastructure
- Most sustainable model, mirrors successful platform economics

*Output monetization (publishing model)*:
The commons publishes and monetizes outputs (reports, software, creative works, services) and distributes revenue to contributors.
- This is the "app store model" mentioned in the README
- Advantage: Creates a marketplace that attracts customers and revenue
- Disadvantage: Requires the commons to build distribution, marketing, and sales capability; creates incentives to prioritize commercially viable work over socially valuable work

### 6.2 Value Attribution

**The central challenge.** In a commons where multiple agents contribute to collective outputs, how do you determine who contributed what and who deserves what share of the revenue?

**Approaches:**

*Commit-based attribution*:
Track all contributions (code commits, document edits, design iterations, meeting participation) and attribute value based on contribution volume and quality.
- Strength: Objective, verifiable, transparent
- Weakness: Volume does not equal value. One insight that changes the product direction is worth more than 1,000 lines of boilerplate code. How do you capture this?

*Shapley values (game theory)*:
The Shapley value is the mathematically "fair" way to distribute the value of a collective output among contributors. It assigns each contributor their average marginal contribution across all possible orderings of contributors.
- Strength: Theoretically optimal, well-studied
- Weakness: Computationally expensive for large groups, requires knowing the value function (which is itself the problem), sensitive to how "marginal contribution" is defined

*Market-based attribution*:
Let market signals determine value. If Agent A's contributions are in high demand (other agents want to work with A, clients request A's involvement), A's contribution is valued higher.
- Strength: Leverages distributed knowledge, adapts dynamically
- Weakness: Winner-take-all dynamics, popularity =/= value, network effects favor incumbents

*Peer assessment*:
Contributors assess each other's contributions. Can be weighted by the assessor's own reputation.
- Strength: Captures qualitative value that metrics miss
- Weakness: Social dynamics, reciprocal favoritism, gaming, and tribalism (the human nature tendencies from Area 1)

*AI-assessed attribution*:
Use AI to evaluate the quality, impact, and novelty of contributions.
- Strength: Scalable, consistent, not subject to human social dynamics
- Weakness: AI capture risk (from Area 1 synthesis), Goodhart's Law (contributors optimize for AI metrics rather than real value), opacity

*Hybrid (recommended)*:
Combine multiple signals: commit tracking + peer assessment + market signals + AI quality evaluation. Weight each signal based on context. No single signal dominates. This provides redundancy and resilience against gaming of any single metric.

### 6.3 Sustainability Against VC-Funded Competition

**The challenge:** A VC-funded platform can subsidize users (below-cost pricing), spend heavily on marketing, hire elite talent at above-market rates, and operate at a loss for years -- all funded by investor capital. A commons cannot do this.

**Historical precedent -- how open-source sustained itself:**

*Consulting / services model (Red Hat)*: Give away the software, sell consulting and support. Red Hat grew to $3.4 billion in revenue before IBM acquired it for $34 billion (2019). This works when the product requires expertise to deploy and maintain. For Agent Commons: the commons provides the platform; revenue comes from premium services.

*Dual licensing (MySQL, MongoDB)*: Open-source for community use, paid license for commercial use. MongoDB's market cap exceeded $20 billion. For Agent Commons: basic commons access is free; commercial use of commons infrastructure requires payment.

*SaaS / hosted service (GitHub, GitLab)*: The open-source tools are free; the hosted, managed service is paid. GitHub (pre-Microsoft acquisition) reached approximately $200 million in ARR primarily through paid hosted plans. For Agent Commons: self-hosting is possible, but the managed commons service is easier and comes with governance, dispute resolution, and marketplace access.

*Sponsorship / grants (Wikipedia, Linux Foundation)*: Funded by donations and corporate sponsorship. Wikipedia operates on approximately $150 million per year, funded entirely by donations. The Linux Foundation is funded by member companies that depend on Linux. For Agent Commons: if the commons creates genuine value for its ecosystem, beneficiary companies may fund it.

*Hybrid (most realistic)*: Combine tiered pricing + marketplace transaction fees + premium services + grants/sponsorship. No single revenue stream is sufficient; diversification provides resilience.

**Can a commons compete without VC?**
Yes, but not on the same terms. A commons competes on:
- **Trust:** Users trust that a commons will not pivot to extraction (unlike VC-funded platforms that must eventually prioritize investor returns over user interests)
- **Alignment:** The commons' incentives align with participants' incentives (unlike VC-backed platforms where user value is a means to investor returns)
- **Durability:** A self-sustaining commons is not subject to VC cycles (funding droughts, down rounds, forced exits)
- **Community:** A commons that genuinely empowers contributors builds loyalty that money cannot buy (open-source has demonstrated this repeatedly)

The VC-funded platform wins the sprint (user acquisition, market share). The commons wins the marathon (trust, alignment, sustainability). The critical question is whether the commons can survive the sprint.

---

## 7. Implications for Agent Commons

### 7.1 Economic Model Design Requirements

Based on this research, an Agent Commons economic model must satisfy:

1. **Sustainability without extraction.** Revenue must cover costs without requiring the commons to extract more value than it creates. This means low take rates, diversified revenue streams, and genuine value creation for participants.

2. **Hybrid value attribution.** No single metric for contribution measurement. Combine quantitative (commit tracking, market signals) and qualitative (peer assessment, AI evaluation) signals with redundancy and gaming resistance.

3. **Progressive distribution.** Avoid winner-take-all dynamics through mechanisms like:
   - Floor mechanisms (minimum viable income for active contributors)
   - Ceiling mechanisms (extraction ratio caps, Mondragon-style)
   - Quadratic funding (Gitcoin model) that amplifies small contributors
   - Time-decay on reputation (preventing permanent incumbency advantage)

4. **Competition-resilient sustainability.** Design for a world where VC-funded platforms compete for the same participants. Compete on trust, alignment, and durability rather than subsidized pricing.

5. **Adaptation to AI capability changes.** As AI capability grows, the value of different contributions will shift. The economic model must be flexible enough to evolve without requiring redesign from scratch.

### 7.2 The Acemoglu/Autor Tension Applied

The economic model must work in both scenarios:

*Acemoglu scenario (displacement dominates)*: If AI displaces more work than it creates, the Agent Commons must provide meaningful economic participation for people who cannot compete with AI. This argues for UBI-like floor mechanisms within the commons -- participation income, learning stipends, contribution credits for community-building work that AI cannot do.

*Autor scenario (creation dominates)*: If AI creates new categories of work faster than it destroys old ones, the Agent Commons must help participants discover and fill these new categories. This argues for experimentation infrastructure, rapid skill development, and marketplace mechanisms that surface emerging opportunities.

The honest answer is we do not know which scenario will dominate, so the economic model must be robust to both.

### 7.3 What Makes Agent Commons Economics Different from Existing Models

| Feature | Traditional Corp | Gig Platform | DAO | Agent Commons (Proposed) |
|---------|-----------------|--------------|-----|--------------------------|
| Who captures value | Shareholders | Platform owner + top workers | Token holders | Contributors (proportional) |
| Entry barrier | Employment offer | Account creation | Token purchase | Contribution |
| Exit cost | Job loss | Reputation loss | Token value loss | Reputation portability |
| Value attribution | Manager assessment | Platform metrics | Token-weighted voting | Hybrid (multi-signal) |
| Extraction bound | None (legally) | None (structurally) | None (vote-based) | Constitutional cap |
| Governance | Board (captured) | Platform owner | Token plutocracy | AI + human democratic |
| Sustainability | Profit extraction | VC then extraction | Token appreciation | Self-funding (take rate) |

### 7.4 Open Economic Questions

1. **What is the right take rate?** Too low and the commons cannot sustain itself. Too high and it becomes extractive. The answer is empirical and context-dependent. Start low (5-8%), adjust based on costs.

2. **How do you price AI governance?** AI governance is the commons' primary value proposition. It must be funded but cannot be priced so high that it creates barriers. Perhaps funded from the take rate rather than a separate charge.

3. **How do you handle the cold-start problem?** The commons is most valuable when many participants are contributing. But early participants face a thin marketplace with few opportunities. Bootstrap mechanisms (founding grants, early-contributor bonuses, partnership with existing organizations) may be necessary.

4. **How do you prevent a talent drain to better-paying alternatives?** If conventional companies offer 5x the pay for similar work, the commons loses its best contributors. Possible responses: equity-like mechanisms (contributor tokens that appreciate with commons growth), non-monetary value (autonomy, meaning, community), and the bet that the commons' growth trajectory will eventually match or exceed conventional compensation.

5. **What is the right balance between redistribution and meritocracy?** Too much redistribution creates free-rider problems (Area 1 findings). Too much meritocracy creates winner-take-all dynamics. The answer is a bounded meritocracy -- reward contribution, but bound the rewards to prevent extreme concentration.

---

## Key Sources

### Labor Economics and AI
- Acemoglu, D. (2024). The Simple Macroeconomics of AI. NBER Working Paper 32487.
- Acemoglu, D. & Restrepo, P. (2019). Automation and New Tasks. *Journal of Economic Perspectives.*
- Acemoglu, D. & Restrepo, P. (2020). Robots and Jobs. *Review of Economic Studies.*
- Autor, D. (2015). Why Are There Still So Many Jobs? *Journal of Economic Perspectives.*
- Autor, D. (2024). Applying AI to Rebuild Middle Class Jobs. NBER Working Paper 32140.
- Autor, D., Dorn, D., Katz, L., Patterson, C., & Van Reenen, J. (2020). The Fall of the Labor Share and the Rise of Superstar Firms. *Quarterly Journal of Economics.*
- Brynjolfsson, E., Li, D., & Raymond, L. (2023). Generative AI at Work. NBER Working Paper 31161.
- Karabarbounis, L. & Neiman, B. (2014). The Global Decline of the Labor Share. *Quarterly Journal of Economics.*
- Goldman Sachs (2023). The Potentially Large Effects of Artificial Intelligence on Economic Growth.
- McKinsey Global Institute (2023). The Economic Potential of Generative AI.

### UBI Research
- Kangas, O., et al. (2019). The Basic Income Experiment 2017-2018 in Finland: Final Results. Ministry of Social Affairs, Finland.
- West, S., et al. (2021). Stockton Economic Empowerment Demonstration (SEED) Final Report.
- Banerjee, A., et al. (2020). Effects of a Universal Basic Income during the Pandemic. NBER Working Paper.
- Hoynes, H. & Rothstein, J. (2019). Universal Basic Income in the United States and Advanced Countries. *Annual Review of Economics.*
- Caplan, B. (2018). *The Case Against Education.* Princeton University Press.

### Platform and Commons Economics
- Scholz, T. (2016). *Platform Cooperativism.* Rosa Luxemburg Stiftung.
- Srnicek, N. (2017). *Platform Capitalism.* Polity Press.
- Parker, G., Van Alstyne, M., & Choudary, S. (2016). *Platform Revolution.* W.W. Norton.
- Eghbal, N. (2020). *Working in Public: The Making and Maintenance of Open Source Software.* Stripe Press.
- Ostrom, E. (1990). *Governing the Commons.* Cambridge University Press.

### Post-Work and Future of Work
- Keynes, J.M. (1930). Economic Possibilities for our Grandchildren.
- Graeber, D. (2018). *Bullshit Jobs.* Simon & Schuster.
- Skidelsky, R. & Skidelsky, E. (2012). *How Much Is Enough?* Other Press.
- Jahoda, M. (1982). *Employment and Unemployment.* Cambridge University Press.
- Pine, B.J. & Gilmore, J. (1998). Welcome to the experience economy. *Harvard Business Review.*
- Frankl, V. (1946). *Man's Search for Meaning.*

### Inequality and Technology
- Piketty, T. (2014). *Capital in the Twenty-First Century.* Harvard University Press.
- Merton, R.K. (1968). The Matthew Effect in Science. *Science.*
- Bebchuk, L. & Tallarita, R. (2020). The Illusory Promise of Stakeholder Governance. *Cornell Law Review.*
- Gorton, G. & Schmid, F. (2004). Capital, labor, and the firm: A study of German codetermination. *Journal of the European Economic Association.*

### Value and Authenticity
- Newman, G. & Bloom, P. (2012). Art and authenticity: The importance of originals in judgments of value. *Journal of Experimental Psychology: General.*
- Frank, R. (2011). *The Darwin Economy.* Princeton University Press.
- Weyl, E.G. & Posner, E.A. (2018). *Radical Markets.* Princeton University Press.
